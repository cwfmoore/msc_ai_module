{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca9628a",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54bb972",
   "metadata": {},
   "source": [
    "## 1.A Summary\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**k-Nearest Neighbours Implementation Summary**</span>\n",
    "\n",
    "This notebook implements **k-Nearest Neighbours (k-NN)** classification to predict student withdrawal risk using the preprocessed student dataset.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**1. Algorithm Overview**</span>\n",
    "\n",
    "**k-Nearest Neighbours** is a **non-parametric, instance-based learning algorithm** that makes predictions by:\n",
    "- Finding the k closest data points to a new instance\n",
    "- Using majority voting amongst these neighbours to determine classification\n",
    "- Making no assumptions about the underlying data distribution\n",
    "\n",
    "**Key characteristics:**\n",
    "- **Lazy learning**: No explicit training phase - stores all data points\n",
    "- **Distance-based**: Uses similarity measures (typically Euclidean distance)\n",
    "- **Local decision boundaries**: Adapts to local patterns in the data\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**2. Binary Classification Setup**</span>\n",
    "\n",
    "**Target transformation**: Combined \"Graduate\" and \"Enrolled\" into \"Continuation\" (1), with \"Dropout\" as \"Withdrawn\" (0), creating a balanced 68:32 class distribution suitable for k-NN's majority voting mechanism.\n",
    "\n",
    "**Dataset**: 4,424 students with preprocessed features ready for distance-based classification.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**3. Preprocessing Requirements**</span>\n",
    "\n",
    "**Essential for k-NN performance:**\n",
    "- **Feature scaling**: StandardScaler applied to prevent features with larger ranges from dominating distance calculations\n",
    "- **One-hot encoding**: Categorical features converted to binary dummy variables\n",
    "- **Feature selection**: Remove redundant and uninformative features identified in earlier analysis\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**4. Model Configuration**</span>\n",
    "\n",
    "**Hyperparameter tuning** focuses on:\n",
    "- **k value**: Number of neighbours to consider (typically odd numbers to avoid ties)\n",
    "- **Distance metric**: Euclidean distance for continuous features\n",
    "- **Weighting scheme**: Uniform vs distance-weighted voting\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**Expected Outcomes**</span>\n",
    "\n",
    "This implementation will evaluate k-NN's effectiveness for student dropout prediction, comparing performance against logistic regression whilst addressing the algorithm's sensitivity to feature scaling and dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b623de",
   "metadata": {},
   "source": [
    "## 1.B Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "a80f1aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import Tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0802855f",
   "metadata": {},
   "source": [
    "## 1.C Invoke Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "57517472",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = Tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6050d",
   "metadata": {},
   "source": [
    "## 1.D Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "69c6b84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:00:50</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">SUCCESS!</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Loaded configuration </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NUMBER OF KEYS</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> \u001b[1m[\u001b[0m\u001b[1;92m22:00:50\u001b[0m\u001b[1m]\u001b[0m \u001b[1;32mSUCCESS!\u001b[0m\u001b[1;37m: \u001b[0m\u001b[1;33mLoaded configuration \u001b[0m\u001b[1;35mNUMBER OF KEYS\u001b[0m\u001b[1;33m: \u001b[0m\u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = tools.load_toml_file(\"config.toml\")\n",
    "tools.print_message('success', 'Loaded configuration', format_dict={'number of keys': len(config)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a6159",
   "metadata": {},
   "source": [
    "## 1.E Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "a5301ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marital_status</th>\n",
       "      <th>application_mode</th>\n",
       "      <th>application_order</th>\n",
       "      <th>course</th>\n",
       "      <th>daytime_evening_attendance</th>\n",
       "      <th>previous_qualification</th>\n",
       "      <th>previous_qualification_grade</th>\n",
       "      <th>nationality</th>\n",
       "      <th>mothers_qualification</th>\n",
       "      <th>fathers_qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>curricular_units_2nd_sem_credited</th>\n",
       "      <th>curricular_units_2nd_sem_enrolled</th>\n",
       "      <th>curricular_units_2nd_sem_evaluations</th>\n",
       "      <th>curricular_units_2nd_sem_approved</th>\n",
       "      <th>curricular_units_2nd_sem_grade</th>\n",
       "      <th>curricular_units_2nd_sem_without_evaluations</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>inflation_rate</th>\n",
       "      <th>gdp</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   marital_status  application_mode  application_order  course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "\n",
       "   daytime_evening_attendance  previous_qualification  \\\n",
       "0                           1                       1   \n",
       "1                           1                       1   \n",
       "2                           1                       1   \n",
       "3                           1                       1   \n",
       "4                           0                       1   \n",
       "\n",
       "   previous_qualification_grade  nationality  mothers_qualification  \\\n",
       "0                         122.0            1                     19   \n",
       "1                         160.0            1                      1   \n",
       "2                         122.0            1                     37   \n",
       "3                         122.0            1                     38   \n",
       "4                         100.0            1                     37   \n",
       "\n",
       "   fathers_qualification  ...  curricular_units_2nd_sem_credited  \\\n",
       "0                     12  ...                                  0   \n",
       "1                      3  ...                                  0   \n",
       "2                     37  ...                                  0   \n",
       "3                     37  ...                                  0   \n",
       "4                     38  ...                                  0   \n",
       "\n",
       "   curricular_units_2nd_sem_enrolled  curricular_units_2nd_sem_evaluations  \\\n",
       "0                                  0                                     0   \n",
       "1                                  6                                     6   \n",
       "2                                  6                                     0   \n",
       "3                                  6                                    10   \n",
       "4                                  6                                     6   \n",
       "\n",
       "   curricular_units_2nd_sem_approved  curricular_units_2nd_sem_grade  \\\n",
       "0                                  0                        0.000000   \n",
       "1                                  6                       13.666667   \n",
       "2                                  0                        0.000000   \n",
       "3                                  5                       12.400000   \n",
       "4                                  6                       13.000000   \n",
       "\n",
       "   curricular_units_2nd_sem_without_evaluations  unemployment_rate  \\\n",
       "0                                             0               10.8   \n",
       "1                                             0               13.9   \n",
       "2                                             0               10.8   \n",
       "3                                             0                9.4   \n",
       "4                                             0               13.9   \n",
       "\n",
       "   inflation_rate   gdp    target  \n",
       "0             1.4  1.74   Dropout  \n",
       "1            -0.3  0.79  Graduate  \n",
       "2             1.4  1.74   Dropout  \n",
       "3            -0.8 -3.12  Graduate  \n",
       "4            -0.3  0.79  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open dataset\n",
    "# Realinho, V., Martins, M.V., Machado, J. and Baptista, L.M.T., 2021. Predict Students' Dropout and Academic Success. UCI Machine Learning Repository. Available at: https://doi.org/10.24432/C5MC89 [Accessed 31 May 2025].\n",
    "df_dataset = tools.load_dataset(file_name='dataset_raw.csv')\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba843dd",
   "metadata": {},
   "source": [
    "## 1.F Apply Target Binary Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "9df09cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_binary\n",
       "1    3003\n",
       "0    1421\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new target column with renamed values for one vs rest classification\n",
    "df_dataset['target_binary'] = df_dataset['target'].map({'Dropout': 0, 'Graduate': 1, 'Enrolled': 1})\n",
    "df_dataset['target_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e260011",
   "metadata": {},
   "source": [
    "## 1.G Data Shape Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a25cbb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:00:50</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">SUCCESS!</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Dataset loaded </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ROWS</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4424</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">, </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">COLUMNS</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> \u001b[1m[\u001b[0m\u001b[1;92m22:00:50\u001b[0m\u001b[1m]\u001b[0m \u001b[1;32mSUCCESS!\u001b[0m\u001b[1;37m: \u001b[0m\u001b[1;33mDataset loaded \u001b[0m\u001b[1;35mROWS\u001b[0m\u001b[1;33m: \u001b[0m\u001b[1;36m4424\u001b[0m\u001b[1;33m, \u001b[0m\u001b[1;35mCOLUMNS\u001b[0m\u001b[1;33m: \u001b[0m\u001b[1;36m38\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shape = df_dataset.shape\n",
    "tools.print_message('success', 'Dataset loaded', format_dict={'rows': shape[0], 'columns': shape[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031bf35e",
   "metadata": {},
   "source": [
    "# 2. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d7e507",
   "metadata": {},
   "source": [
    "## 2.A Summary\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**Feature Selection for k-Nearest Neighbours**</span>\n",
    "\n",
    "This analysis reduced the dataset from 36 original features to 10 carefully selected features optimised for k-NN performance. The selection process addressed key challenges including data leakage, multicollinearity, and the curse of dimensionality.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**1. Data Leakage Prevention**</span>\n",
    "\n",
    "**Data leakage** occurs when we accidentally include information that wouldn't be available when making real predictions. In our student withdrawal dataset, second semester data creates severe leakage issues.\n",
    "\n",
    "**The Problem:**\n",
    "- Students who withdraw during first semester have **zero values** for all second semester metrics\n",
    "- These zeros perfectly identify withdrawn students - but only **after** withdrawal has occurred\n",
    "- Using 2nd semester features gives artificially high accuracy but useless real-world predictions\n",
    "\n",
    "**Solution Applied:**\n",
    "- **Removed ALL second semester features**: grades, credited units, enrolled units, approved units, evaluations\n",
    "- **Kept first semester features**: These represent genuine early warning indicators available during the semester\n",
    "- **Focus on early intervention**: The model can now predict withdrawals using information available **before** students drop out\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**2. Multicollinearity Resolution**</span>\n",
    "\n",
    "**Multicollinearity** occurs when features provide nearly identical information, measured by **Variance Inflation Factor (VIF)**. High VIF values harm k-NN performance by:\n",
    "- Creating redundant dimensions in distance calculations\n",
    "- Amplifying noise and reducing accuracy\n",
    "- Making feature scaling less effective\n",
    "\n",
    "**Problematic Features Removed:**\n",
    "- `curricular_units_1st_sem_enrolled` (VIF: 23.49)\n",
    "- `curricular_units_1st_sem_credited` (VIF: 15.57)  \n",
    "- `curricular_units_1st_sem_approved` (VIF: 12.63)\n",
    "\n",
    "**Kept:** `curricular_units_1st_sem_grade` (VIF: 4.98) - represents actual academic performance without multicollinearity issues.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**3. High Cardinality Feature Engineering**</span>\n",
    "\n",
    "**High cardinality features** (many categories) create severe problems for k-NN. Two different encoding strategies were applied:\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**Parental Background - Binary Grouping:**</span>\n",
    "- Parents' **qualifications** had **29 categories each**\n",
    "- Parents' **occupations** had **46 categories each**\n",
    "- After one-hot encoding, this would create **150 new binary features** (29+29+46+46)\n",
    "\n",
    "**Solution Applied:**\n",
    "```python\n",
    "# Reduced 4 high-cardinality features to 2 meaningful binary indicators:\n",
    "parental_higher_education          # Combines 58 education categories\n",
    "parental_professional_occupation   # Combines 92 occupation categories\n",
    "```\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**Academic Context - Withdrawal Rate Encoding:**</span>\n",
    "- `course`: 17 different programmes of study\n",
    "- `application_mode`: 18 different admission routes\n",
    "\n",
    "**Solution Applied:**\n",
    "```python\n",
    "# Target encoding using withdrawal rates for each category:\n",
    "course_withdrawal_rate              # Each course gets its historical withdrawal rate\n",
    "application_mode_withdrawal_rate    # Each application route gets its withdrawal rate\n",
    "```\n",
    "\n",
    "**Benefits of Withdrawal Rate Encoding:**\n",
    "- **Reduces dimensionality**: 17 course categories → 1 continuous feature\n",
    "- **Preserves predictive power**: Directly captures risk level of each category\n",
    "- **Interpretable results**: Higher values = higher risk groups\n",
    "- **k-NN friendly**: Creates meaningful distance measurements between similar risk levels\n",
    "\n",
    "**Overall Benefits:**\n",
    "- Captures meaningful background and context information\n",
    "- Reduces dimensionality from 150+ to 4 features\n",
    "- Maintains predictive power whilst eliminating noise\n",
    "- Creates continuous features suitable for distance calculations\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**4. Uninformative Feature Removal**</span>\n",
    "\n",
    "**Severely imbalanced features** provide little predictive value:\n",
    "- `nationality`: 97.5% Portuguese students\n",
    "- `educational_special_needs`: 98.9% have no special needs\n",
    "- `international`: 97.5% domestic students\n",
    "\n",
    "**Weak predictors** with minimal correlation to target:\n",
    "- Economic indicators: unemployment, inflation, GDP (correlations -0.03 to 0.05)\n",
    "- `previous_qualification_grade`: correlation 0.08\n",
    "\n",
    "These features add noise without improving k-NN accuracy.\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**Why 10 Features is Optimal for k-NN**</span>\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**1. Curse of Dimensionality**</span>\n",
    "**The curse of dimensionality** means that as feature count increases, data points become increasingly distant from each other, making similarity measurements meaningless. With too many features:\n",
    "- All students appear equally \"different\" from each other\n",
    "- Nearest neighbours become arbitrary rather than truly similar\n",
    "- Model performance degrades despite having more information\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**2. Distance Calculation Efficiency**</span>\n",
    "k-NN calculates distances between data points using all features. With 10 features:\n",
    "- **Computational efficiency**: Distance calculations remain fast\n",
    "- **Feature scaling effectiveness**: Each feature has meaningful impact on similarity\n",
    "- **Interpretable results**: Easy to understand why students are classified as similar\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**3. Signal-to-Noise Ratio**</span>\n",
    "Ten carefully selected features provide:\n",
    "- **Strong signal**: Each feature contributes meaningful predictive information\n",
    "- **Minimal noise**: Removed redundant and weak predictors\n",
    "- **Balanced representation**: Academic, financial, demographic, and family factors\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**Final 10 Features Selected**</span>\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**Financial Predictors (2 features):**</span>\n",
    "- `tuition_fees_up_to_date` - strongest single predictor\n",
    "- `scholarship_holder` - financial support indicator\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**Academic Context (3 features):**</span>\n",
    "- `course_withdrawal_rate` - programme risk level\n",
    "- `application_mode_withdrawal_rate` - admission route risk level\n",
    "- `application_order` - preference ranking\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**Performance Indicators (2 features):**</span>\n",
    "- `curricular_units_1st_sem_grade` - academic achievement\n",
    "- `age_at_enrollment` - maturity/readiness indicator\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**Background Factors (2 features):**</span>\n",
    "- `parental_higher_education` - family education background\n",
    "- `parental_professional_occupation` - family socio-economic status\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**Pre-enrollment Predictor (1 feature):**</span>\n",
    "- `admission_grade` - academic preparation\n",
    "\n",
    "This feature selection enables k-NN to identify truly similar students based on meaningful characteristics whilst avoiding the pitfalls of high-dimensional data and data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27365dea",
   "metadata": {},
   "source": [
    "## 2.B Features to Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "cdcf9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Severe class imbalance makes these features uninformative\n",
    "uninformative_categorical = [\n",
    "    'nationality',                    # 97.5% Portuguese - no variation\n",
    "    'educational_special_needs',      # 98.9% no special needs - no variation\n",
    "    'international',                  # 97.5% domestic - no variation\n",
    "    'displaced',                      # Zero mutual information with target\n",
    "    'daytime_evening_attendance'      # Zero mutual information with target\n",
    "]\n",
    "\n",
    "# Very weak correlation with target variable makes these unhelpful\n",
    "weak_economic_features = [\n",
    "    'unemployment_rate',              # -0.03 correlation - essentially no relationship\n",
    "    'inflation_rate',                 # 0.02 correlation - essentially no relationship\n",
    "    'gdp'                            # 0.05 correlation - essentially no relationship\n",
    "]\n",
    "\n",
    "# Data leakage - using information that only exists after the outcome has occurred\n",
    "second_semester_remove = [\n",
    "    'curricular_units_2nd_sem_grade',           # VIF 5.46 but still data leakage\n",
    "    'curricular_units_2nd_sem_enrolled',        # VIF 16.42\n",
    "    'curricular_units_2nd_sem_credited',        # VIF 12.39\n",
    "    'curricular_units_2nd_sem_approved',        # VIF 10.14\n",
    "    'curricular_units_2nd_sem_evaluations',     # VIF 3.33\n",
    "    'curricular_units_2nd_sem_without_evaluations'  # VIF 1.57\n",
    "]\n",
    "\n",
    "# Remove HIGH VIF 1st semester features (>10) to fix multicollinearity\n",
    "first_semester_high_vif_remove = [\n",
    "    'curricular_units_1st_sem_enrolled',        # VIF 23.49 (WORST)\n",
    "    'curricular_units_1st_sem_credited',        # VIF 15.57 \n",
    "    'curricular_units_1st_sem_approved'         # VIF 12.63\n",
    "]\n",
    "\n",
    "# Features to remove for final k-NN model - keeping only top 10 predictive features\n",
    "features_to_remove_final = [\n",
    "    'marital_status',                           # Weaker categorical predictor\n",
    "    'previous_qualification',                   # Weaker categorical predictor  \n",
    "    'previous_qualification_grade',             # Weak correlation (0.08)\n",
    "    'debtor',                                  # Redundant with tuition_fees_up_to_date\n",
    "    'gender',                                  # Weaker categorical predictor\n",
    "    'curricular_units_1st_sem_evaluations',   # Moderate but less critical\n",
    "    'curricular_units_1st_sem_without_evaluations',  # Moderate but less critical\n",
    "\n",
    "    'target'                                 # Old target variable (replaced with target_binary) - no longer needed\n",
    "]\n",
    "\n",
    "# Combine all features to drop\n",
    "drop_columns = (uninformative_categorical + weak_economic_features + \n",
    "                second_semester_remove + first_semester_high_vif_remove + \n",
    "                features_to_remove_final)\n",
    "\n",
    "df_dataset.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78841938",
   "metadata": {},
   "source": [
    "## 2.C Reduce High Cardinality Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "1cd626e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining parental features: ['mothers_qualification', 'fathers_qualification', 'mothers_occupation', 'fathers_occupation']\n"
     ]
    }
   ],
   "source": [
    "# Check if parental features still exist in dataset\n",
    "parental_features = ['mothers_qualification', 'fathers_qualification', 'mothers_occupation', 'fathers_occupation']\n",
    "existing_features = [f for f in parental_features if f in df_dataset.columns]\n",
    "print(f\"Remaining parental features: {existing_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "73ba7457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parental_higher_education\n",
       "0    3616\n",
       "1     808\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To reduce the number of categories in the parental qualification and occupation features, we will group them into broader categories.\n",
    "def create_parental_higher_ed(df):\n",
    "    \"\"\"\n",
    "    Creates binary indicator for parental higher education.\n",
    "    Returns 1 if at least one parent has higher education, 0 otherwise.\n",
    "    \"\"\"\n",
    "    higher_ed_codes = [2, 3, 4, 5, 6, 39, 40, 41, 42, 43, 44]\n",
    "    \n",
    "    mother_higher_ed = df['mothers_qualification'].isin(higher_ed_codes)\n",
    "    father_higher_ed = df['fathers_qualification'].isin(higher_ed_codes)\n",
    "    \n",
    "    # At least one parent has higher education\n",
    "    df['parental_higher_education'] = (mother_higher_ed | father_higher_ed).astype(int)\n",
    "    df = df.drop(columns=['mothers_qualification', 'fathers_qualification'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage:\n",
    "df_dataset = create_parental_higher_ed(df_dataset)\n",
    "df_dataset.parental_higher_education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "45f5ce9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parental_professional_occupation\n",
       "0    3270\n",
       "1    1154\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_parental_professional_occupation(df):\n",
    "    \"\"\"\n",
    "    Creates binary indicator for parental professional occupation.\n",
    "    Returns 1 if at least one parent has professional/managerial role, 0 otherwise.\n",
    "    \"\"\"\n",
    "    professional_codes = [1, 2, 3, 101, 102, 112, 114, 121, 122, 123, 124, \n",
    "                          131, 132, 134, 135]\n",
    "    \n",
    "    mother_professional = df['mothers_occupation'].isin(professional_codes)\n",
    "    father_professional = df['fathers_occupation'].isin(professional_codes)\n",
    "    \n",
    "    # At least one parent has professional occupation\n",
    "    df['parental_professional_occupation'] = (mother_professional | father_professional).astype(int)\n",
    "    df = df.drop(columns=['mothers_occupation', 'fathers_occupation'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage:\n",
    "df_dataset = create_parental_professional_occupation(df_dataset)\n",
    "df_dataset.parental_professional_occupation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "a28db662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after parental feature engineering: (4424, 11)\n",
      "Remaining features: ['application_mode', 'application_order', 'course', 'admission_grade', 'tuition_fees_up_to_date', 'scholarship_holder', 'age_at_enrollment', 'curricular_units_1st_sem_grade', 'target_binary', 'parental_higher_education', 'parental_professional_occupation']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset shape after parental feature engineering: {df_dataset.shape}\")\n",
    "print(f\"Remaining features: {df_dataset.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "4770645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_withdrawal_rate(df, cat_col, target_col='target_binary'):\n",
    "    \"\"\"\n",
    "    Replace categorical column with withdrawal rate encoding.\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    cat_col: name of categorical column to encode\n",
    "    target_col: name of target column where 0=withdrawn\n",
    "    \n",
    "    Returns:\n",
    "    pandas DataFrame with categorical column replaced by withdrawal_rate\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    # Calculate withdrawal rate for each category\n",
    "    withdrawal_rates = (df[target_col] == 0).groupby(df[cat_col]).mean()\n",
    "    \n",
    "    # Create new withdrawal rate column\n",
    "    new_col_name = f'{cat_col.lower().replace(\" \", \"_\")}_withdrawal_rate'\n",
    "    df_encoded[new_col_name] = df[cat_col].map(withdrawal_rates)\n",
    "    \n",
    "    # Remove original column\n",
    "    df_encoded = df_encoded.drop(columns=[cat_col])\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "# Usage:\n",
    "df_dataset = encode_categorical_withdrawal_rate(df_dataset, 'application_mode')\n",
    "df_dataset = encode_categorical_withdrawal_rate(df_dataset, 'course')\n",
    "df_dataset.describe().to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756c0df8",
   "metadata": {},
   "source": [
    "# 3. Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "841f9b33",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[367]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      4\u001b[39m features_to_scale = [\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mapplication_order\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33madmission_grade\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mage_at_enrollment\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcurricular_units_1st_sem_grade\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m ]\n\u001b[32m     11\u001b[39m scaler = StandardScaler()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m X_scaled = \u001b[43mX\u001b[49m.copy()\n\u001b[32m     13\u001b[39m X_scaled[features_to_scale] = scaler.fit_transform(X[features_to_scale])\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Only these 4 features need scaling\n",
    "features_to_scale = [\n",
    "    'application_order', \n",
    "    'admission_grade', \n",
    "    'age_at_enrollment',\n",
    "    'curricular_units_1st_sem_grade'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "X_scaled[features_to_scale] = scaler.fit_transform(X[features_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9092913c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[354]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Create and fit scaler\u001b[39;00m\n\u001b[32m     12\u001b[39m scaler = StandardScaler()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m X_scaled = \u001b[43mX\u001b[49m.copy()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Scale only the features that need it\u001b[39;00m\n\u001b[32m     16\u001b[39m X_scaled[features_to_scale] = scaler.fit_transform(X[features_to_scale])\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Features that need scaling (different ranges)\n",
    "features_to_scale = [\n",
    "    'application_order', \n",
    "    'admission_grade', \n",
    "    'age_at_enrollment',\n",
    "    'curricular_units_1st_sem_grade'\n",
    "]\n",
    "\n",
    "# Create and fit scaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "\n",
    "# Scale only the features that need it\n",
    "X_scaled[features_to_scale] = scaler.fit_transform(X[features_to_scale])\n",
    "\n",
    "# Check the results\n",
    "print(\"Before scaling - ranges:\")\n",
    "print(X[features_to_scale].describe())\n",
    "print(\"\\nAfter scaling - should be mean≈0, std≈1:\")\n",
    "print(X_scaled[features_to_scale].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
