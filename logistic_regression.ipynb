{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f45e2fe",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562ef62b",
   "metadata": {},
   "source": [
    "## 1.A Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd03baeb",
   "metadata": {},
   "source": [
    "## 1.B Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "653eb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project-specific utilities (keep only if used elsewhere)\n",
    "from tools import Tools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b6995",
   "metadata": {},
   "source": [
    "## 1.C Invoke Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84d5d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = Tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ff9f9",
   "metadata": {},
   "source": [
    "## 1.D Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51c3f94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:38:17</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">SUCCESS!</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Loaded configuration </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NUMBER OF KEYS</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> \u001b[1m[\u001b[0m\u001b[1;92m14:38:17\u001b[0m\u001b[1m]\u001b[0m \u001b[1;32mSUCCESS!\u001b[0m\u001b[1;37m: \u001b[0m\u001b[1;33mLoaded configuration \u001b[0m\u001b[1;35mNUMBER OF KEYS\u001b[0m\u001b[1;33m: \u001b[0m\u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = tools.load_toml_file(\"config.toml\")\n",
    "tools.print_message('success', 'Loaded configuration', format_dict={'number of keys': len(config)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08fc02",
   "metadata": {},
   "source": [
    "## 1.E Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02026257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marital_status</th>\n",
       "      <th>application_mode</th>\n",
       "      <th>application_order</th>\n",
       "      <th>course</th>\n",
       "      <th>daytime_evening_attendance</th>\n",
       "      <th>previous_qualification</th>\n",
       "      <th>previous_qualification_grade</th>\n",
       "      <th>nationality</th>\n",
       "      <th>mothers_qualification</th>\n",
       "      <th>fathers_qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>curricular_units_2nd_sem_credited</th>\n",
       "      <th>curricular_units_2nd_sem_enrolled</th>\n",
       "      <th>curricular_units_2nd_sem_evaluations</th>\n",
       "      <th>curricular_units_2nd_sem_approved</th>\n",
       "      <th>curricular_units_2nd_sem_grade</th>\n",
       "      <th>curricular_units_2nd_sem_without_evaluations</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>inflation_rate</th>\n",
       "      <th>gdp</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   marital_status  application_mode  application_order  course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "\n",
       "   daytime_evening_attendance  previous_qualification  \\\n",
       "0                           1                       1   \n",
       "1                           1                       1   \n",
       "2                           1                       1   \n",
       "3                           1                       1   \n",
       "4                           0                       1   \n",
       "\n",
       "   previous_qualification_grade  nationality  mothers_qualification  \\\n",
       "0                         122.0            1                     19   \n",
       "1                         160.0            1                      1   \n",
       "2                         122.0            1                     37   \n",
       "3                         122.0            1                     38   \n",
       "4                         100.0            1                     37   \n",
       "\n",
       "   fathers_qualification  ...  curricular_units_2nd_sem_credited  \\\n",
       "0                     12  ...                                  0   \n",
       "1                      3  ...                                  0   \n",
       "2                     37  ...                                  0   \n",
       "3                     37  ...                                  0   \n",
       "4                     38  ...                                  0   \n",
       "\n",
       "   curricular_units_2nd_sem_enrolled  curricular_units_2nd_sem_evaluations  \\\n",
       "0                                  0                                     0   \n",
       "1                                  6                                     6   \n",
       "2                                  6                                     0   \n",
       "3                                  6                                    10   \n",
       "4                                  6                                     6   \n",
       "\n",
       "   curricular_units_2nd_sem_approved  curricular_units_2nd_sem_grade  \\\n",
       "0                                  0                        0.000000   \n",
       "1                                  6                       13.666667   \n",
       "2                                  0                        0.000000   \n",
       "3                                  5                       12.400000   \n",
       "4                                  6                       13.000000   \n",
       "\n",
       "   curricular_units_2nd_sem_without_evaluations  unemployment_rate  \\\n",
       "0                                             0               10.8   \n",
       "1                                             0               13.9   \n",
       "2                                             0               10.8   \n",
       "3                                             0                9.4   \n",
       "4                                             0               13.9   \n",
       "\n",
       "   inflation_rate   gdp    target  \n",
       "0             1.4  1.74   Dropout  \n",
       "1            -0.3  0.79  Graduate  \n",
       "2             1.4  1.74   Dropout  \n",
       "3            -0.8 -3.12  Graduate  \n",
       "4            -0.3  0.79  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open dataset\n",
    "# Realinho, V., Martins, M.V., Machado, J. and Baptista, L.M.T., 2021. Predict Students' Dropout and Academic Success. UCI Machine Learning Repository. Available at: https://doi.org/10.24432/C5MC89 [Accessed 31 May 2025].\n",
    "df_dataset = tools.load_dataset(file_name='dataset_raw.csv')\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d60678",
   "metadata": {},
   "source": [
    "## 1.F Apply Target Binary Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb179a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_binary\n",
       "1    3003\n",
       "0    1421\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new target column with renamed values for one vs rest classification\n",
    "df_dataset['target_binary'] = df_dataset['target'].map({'Dropout': 0, 'Graduate': 1, 'Enrolled': 1})\n",
    "df_dataset['target_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2cc8f",
   "metadata": {},
   "source": [
    "## 1.G Data Shape Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22c0669c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:38:18</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">SUCCESS!</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Dataset loaded </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ROWS</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4424</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">, </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">COLUMNS</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> \u001b[1m[\u001b[0m\u001b[1;92m14:38:18\u001b[0m\u001b[1m]\u001b[0m \u001b[1;32mSUCCESS!\u001b[0m\u001b[1;37m: \u001b[0m\u001b[1;33mDataset loaded \u001b[0m\u001b[1;35mROWS\u001b[0m\u001b[1;33m: \u001b[0m\u001b[1;36m4424\u001b[0m\u001b[1;33m, \u001b[0m\u001b[1;35mCOLUMNS\u001b[0m\u001b[1;33m: \u001b[0m\u001b[1;36m38\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shape = df_dataset.shape\n",
    "tools.print_message('success', 'Dataset loaded', format_dict={'rows': shape[0], 'columns': shape[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fbab1e",
   "metadata": {},
   "source": [
    "# 2. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e4502",
   "metadata": {},
   "source": [
    "## 2.A Summary\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**Feature Selection for Logistic Regression**</span>\n",
    "\n",
    "This analysis prepared the dataset for Logistic Regression by removing problematic features and encoding categorical variables to create stable, interpretable predictors suitable for linear classification.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**1. Feature Removal Strategy**</span>\n",
    "\n",
    "**Removed 13 features** from original 36:\n",
    "- **Data leakage**: 5 second semester features (students who withdraw early show zeros)\n",
    "- **Severely imbalanced**: Nationality, educational special needs, international status (>97% in one category)\n",
    "- **Zero information**: Daytime/evening attendance, displaced status\n",
    "- **Weak predictors**: Economic indicators, previous qualification grade (correlation <0.10)\n",
    "\n",
    "**Result**: 23 meaningful features suitable for linear classification.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**2. High Cardinality Feature Engineering**</span>\n",
    "\n",
    "**Parents' qualifications and occupations** (150+ total categories) were reduced to **2 binary indicators**:\n",
    "- `parental_higher_education` - at least one parent with higher education\n",
    "- `parental_professional_occupation` - at least one parent in professional role\n",
    "\n",
    "**Benefits**: Captures family background whilst avoiding **coefficient inflation** from too many categories.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**3. Withdrawal Rate Encoding**</span>\n",
    "\n",
    "**Medium cardinality features** were replaced with their historical withdrawal rates:\n",
    "- `application_mode` (18 categories) → `application_mode_withdrawal_rate`\n",
    "- `course` (17 categories) → `course_withdrawal_rate` \n",
    "- `previous_qualification` (17 categories) → `previous_qualification_withdrawal_rate`\n",
    "\n",
    "**Advantage**: Creates continuous predictors where higher values = higher risk, avoiding **sparse matrices** that harm model convergence.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**4. One-Hot Encoding**</span>\n",
    "\n",
    "**Low cardinality features** (2-8 categories) used **one-hot encoding** with `drop_first=True`:\n",
    "- Marital status, application order, gender, scholarship holder, tuition fees status, debtor status\n",
    "- Creates ~15 binary features\n",
    "- **Drop-first prevents multicollinearity** - avoids perfect correlation between category indicators\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**Impact on Logistic Regression**</span>\n",
    "\n",
    "**Model stability**: Strategic encoding prevents **multicollinearity** and **overfitting** whilst maintaining interpretable coefficients. **Early intervention capability**: Uses only first semester data for timely withdrawal prediction. **Regularisation ready**: 25 well-encoded features work effectively with **L1/L2 regularisation** techniques.\n",
    "\n",
    "This feature selection balances predictive power with model stability, creating optimal conditions for Logistic Regression deployment in student retention systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a7235",
   "metadata": {},
   "source": [
    "## 2.B Features to Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfb1a903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:38:18</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">SUCCESS!</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Dropped features </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NUMBER OF FEATURES</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> \u001b[1m[\u001b[0m\u001b[1;92m14:38:18\u001b[0m\u001b[1m]\u001b[0m \u001b[1;32mSUCCESS!\u001b[0m\u001b[1;37m: \u001b[0m\u001b[1;33mDropped features \u001b[0m\u001b[1;35mNUMBER OF FEATURES\u001b[0m\u001b[1;33m: \u001b[0m\u001b[1;36m15\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data leakage - 2nd semester features\n",
    "data_leakage_features = [\n",
    "    'curricular_units_2nd_sem_credited',\n",
    "    'curricular_units_2nd_sem_enrolled', \n",
    "    'curricular_units_2nd_sem_evaluations',\n",
    "    'curricular_units_2nd_sem_approved',\n",
    "    'curricular_units_2nd_sem_grade'\n",
    "]\n",
    "\n",
    "# Severely imbalanced features (>97% in one category)\n",
    "imbalanced_features = [\n",
    "    'nationality',\n",
    "    'educational_special_needs',\n",
    "    'international'\n",
    "]\n",
    "\n",
    "# Zero information value features\n",
    "zero_info_features = [\n",
    "    'daytime_evening_attendance',\n",
    "    'displaced'\n",
    "]\n",
    "\n",
    "# Weak predictors (correlation < 0.10)\n",
    "weak_predictors = [\n",
    "    'unemployment_rate',\n",
    "    'inflation_rate',\n",
    "    'gdp',\n",
    "    'previous_qualification_grade'\n",
    "]\n",
    "\n",
    "# Old target column\n",
    "target_column = ['target']\n",
    "\n",
    "# Combine all features to drop\n",
    "features_to_drop = (data_leakage_features + \n",
    "                   imbalanced_features + \n",
    "                   zero_info_features + \n",
    "                   weak_predictors + \n",
    "                   target_column)\n",
    "\n",
    "df_dataset.drop(columns=features_to_drop, inplace=True, errors='ignore')\n",
    "tools.print_message('success', 'Dropped features', format_dict={'number of features': len(features_to_drop)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5492efe3",
   "metadata": {},
   "source": [
    "## 2.C Reduce High Cardinality Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1340ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining parental features: ['mothers_qualification', 'fathers_qualification', 'mothers_occupation', 'fathers_occupation']\n"
     ]
    }
   ],
   "source": [
    "# Check if parental features still exist in dataset\n",
    "parental_features = ['mothers_qualification', 'fathers_qualification', 'mothers_occupation', 'fathers_occupation']\n",
    "existing_features = [f for f in parental_features if f in df_dataset.columns]\n",
    "print(f\"Remaining parental features: {existing_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6718c901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parental_higher_education\n",
       "0    3616\n",
       "1     808\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To reduce the number of categories in the parental qualification and occupation features, we will group them into broader categories.\n",
    "def create_parental_higher_ed(df):\n",
    "    \"\"\"\n",
    "    Creates binary indicator for parental higher education.\n",
    "    Returns 1 if at least one parent has higher education, 0 otherwise.\n",
    "    \"\"\"\n",
    "    higher_ed_codes = [2, 3, 4, 5, 6, 39, 40, 41, 42, 43, 44]\n",
    "    \n",
    "    mother_higher_ed = df['mothers_qualification'].isin(higher_ed_codes)\n",
    "    father_higher_ed = df['fathers_qualification'].isin(higher_ed_codes)\n",
    "    \n",
    "    # At least one parent has higher education\n",
    "    df['parental_higher_education'] = (mother_higher_ed | father_higher_ed).astype(int)\n",
    "    df = df.drop(columns=['mothers_qualification', 'fathers_qualification'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage:\n",
    "df_dataset = create_parental_higher_ed(df_dataset)\n",
    "df_dataset.parental_higher_education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6ba6264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parental_professional_occupation\n",
       "0    3270\n",
       "1    1154\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_parental_professional_occupation(df):\n",
    "    \"\"\"\n",
    "    Creates binary indicator for parental professional occupation.\n",
    "    Returns 1 if at least one parent has professional/managerial role, 0 otherwise.\n",
    "    \"\"\"\n",
    "    professional_codes = [1, 2, 3, 101, 102, 112, 114, 121, 122, 123, 124, \n",
    "                          131, 132, 134, 135]\n",
    "    \n",
    "    mother_professional = df['mothers_occupation'].isin(professional_codes)\n",
    "    father_professional = df['fathers_occupation'].isin(professional_codes)\n",
    "    \n",
    "    # At least one parent has professional occupation\n",
    "    df['parental_professional_occupation'] = (mother_professional | father_professional).astype(int)\n",
    "    df = df.drop(columns=['mothers_occupation', 'fathers_occupation'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage:\n",
    "df_dataset = create_parental_professional_occupation(df_dataset)\n",
    "df_dataset.parental_professional_occupation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd7b134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after parental feature engineering: (4424, 21)\n",
      "Remaining features: ['marital_status', 'application_mode', 'application_order', 'course', 'previous_qualification', 'admission_grade', 'debtor', 'tuition_fees_up_to_date', 'gender', 'scholarship_holder', 'age_at_enrollment', 'curricular_units_1st_sem_credited', 'curricular_units_1st_sem_enrolled', 'curricular_units_1st_sem_evaluations', 'curricular_units_1st_sem_approved', 'curricular_units_1st_sem_grade', 'curricular_units_1st_sem_without_evaluations', 'curricular_units_2nd_sem_without_evaluations', 'target_binary', 'parental_higher_education', 'parental_professional_occupation']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset shape after parental feature engineering: {df_dataset.shape}\")\n",
    "print(f\"Remaining features: {df_dataset.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f399c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marital_status</th>\n",
       "      <th>application_order</th>\n",
       "      <th>admission_grade</th>\n",
       "      <th>debtor</th>\n",
       "      <th>tuition_fees_up_to_date</th>\n",
       "      <th>gender</th>\n",
       "      <th>scholarship_holder</th>\n",
       "      <th>age_at_enrollment</th>\n",
       "      <th>curricular_units_1st_sem_credited</th>\n",
       "      <th>curricular_units_1st_sem_enrolled</th>\n",
       "      <th>...</th>\n",
       "      <th>curricular_units_1st_sem_approved</th>\n",
       "      <th>curricular_units_1st_sem_grade</th>\n",
       "      <th>curricular_units_1st_sem_without_evaluations</th>\n",
       "      <th>curricular_units_2nd_sem_without_evaluations</th>\n",
       "      <th>target_binary</th>\n",
       "      <th>parental_higher_education</th>\n",
       "      <th>parental_professional_occupation</th>\n",
       "      <th>application_mode_withdrawal_rate</th>\n",
       "      <th>course_withdrawal_rate</th>\n",
       "      <th>previous_qualification_withdrawal_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.178571</td>\n",
       "      <td>1.727848</td>\n",
       "      <td>126.978119</td>\n",
       "      <td>0.113698</td>\n",
       "      <td>0.880651</td>\n",
       "      <td>0.351718</td>\n",
       "      <td>0.248418</td>\n",
       "      <td>23.265145</td>\n",
       "      <td>0.709991</td>\n",
       "      <td>6.270570</td>\n",
       "      <td>...</td>\n",
       "      <td>4.706600</td>\n",
       "      <td>10.640822</td>\n",
       "      <td>0.137658</td>\n",
       "      <td>0.150316</td>\n",
       "      <td>0.678797</td>\n",
       "      <td>0.182640</td>\n",
       "      <td>0.260850</td>\n",
       "      <td>0.321203</td>\n",
       "      <td>0.321203</td>\n",
       "      <td>0.321203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.605747</td>\n",
       "      <td>1.313793</td>\n",
       "      <td>14.482001</td>\n",
       "      <td>0.317480</td>\n",
       "      <td>0.324235</td>\n",
       "      <td>0.477560</td>\n",
       "      <td>0.432144</td>\n",
       "      <td>7.587816</td>\n",
       "      <td>2.360507</td>\n",
       "      <td>2.480178</td>\n",
       "      <td>...</td>\n",
       "      <td>3.094238</td>\n",
       "      <td>4.843663</td>\n",
       "      <td>0.690880</td>\n",
       "      <td>0.753774</td>\n",
       "      <td>0.466991</td>\n",
       "      <td>0.386415</td>\n",
       "      <td>0.439148</td>\n",
       "      <td>0.140266</td>\n",
       "      <td>0.121256</td>\n",
       "      <td>0.099940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154047</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>117.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201991</td>\n",
       "      <td>0.183099</td>\n",
       "      <td>0.290019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293578</td>\n",
       "      <td>0.330233</td>\n",
       "      <td>0.290019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>134.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.381395</td>\n",
       "      <td>0.290019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       marital_status  application_order  admission_grade       debtor  \\\n",
       "count     4424.000000        4424.000000      4424.000000  4424.000000   \n",
       "mean         1.178571           1.727848       126.978119     0.113698   \n",
       "std          0.605747           1.313793        14.482001     0.317480   \n",
       "min          1.000000           0.000000        95.000000     0.000000   \n",
       "25%          1.000000           1.000000       117.900000     0.000000   \n",
       "50%          1.000000           1.000000       126.100000     0.000000   \n",
       "75%          1.000000           2.000000       134.800000     0.000000   \n",
       "max          6.000000           9.000000       190.000000     1.000000   \n",
       "\n",
       "       tuition_fees_up_to_date       gender  scholarship_holder  \\\n",
       "count              4424.000000  4424.000000         4424.000000   \n",
       "mean                  0.880651     0.351718            0.248418   \n",
       "std                   0.324235     0.477560            0.432144   \n",
       "min                   0.000000     0.000000            0.000000   \n",
       "25%                   1.000000     0.000000            0.000000   \n",
       "50%                   1.000000     0.000000            0.000000   \n",
       "75%                   1.000000     1.000000            0.000000   \n",
       "max                   1.000000     1.000000            1.000000   \n",
       "\n",
       "       age_at_enrollment  curricular_units_1st_sem_credited  \\\n",
       "count        4424.000000                        4424.000000   \n",
       "mean           23.265145                           0.709991   \n",
       "std             7.587816                           2.360507   \n",
       "min            17.000000                           0.000000   \n",
       "25%            19.000000                           0.000000   \n",
       "50%            20.000000                           0.000000   \n",
       "75%            25.000000                           0.000000   \n",
       "max            70.000000                          20.000000   \n",
       "\n",
       "       curricular_units_1st_sem_enrolled  ...  \\\n",
       "count                        4424.000000  ...   \n",
       "mean                            6.270570  ...   \n",
       "std                             2.480178  ...   \n",
       "min                             0.000000  ...   \n",
       "25%                             5.000000  ...   \n",
       "50%                             6.000000  ...   \n",
       "75%                             7.000000  ...   \n",
       "max                            26.000000  ...   \n",
       "\n",
       "       curricular_units_1st_sem_approved  curricular_units_1st_sem_grade  \\\n",
       "count                        4424.000000                     4424.000000   \n",
       "mean                            4.706600                       10.640822   \n",
       "std                             3.094238                        4.843663   \n",
       "min                             0.000000                        0.000000   \n",
       "25%                             3.000000                       11.000000   \n",
       "50%                             5.000000                       12.285714   \n",
       "75%                             6.000000                       13.400000   \n",
       "max                            26.000000                       18.875000   \n",
       "\n",
       "       curricular_units_1st_sem_without_evaluations  \\\n",
       "count                                   4424.000000   \n",
       "mean                                       0.137658   \n",
       "std                                        0.690880   \n",
       "min                                        0.000000   \n",
       "25%                                        0.000000   \n",
       "50%                                        0.000000   \n",
       "75%                                        0.000000   \n",
       "max                                       12.000000   \n",
       "\n",
       "       curricular_units_2nd_sem_without_evaluations  target_binary  \\\n",
       "count                                   4424.000000    4424.000000   \n",
       "mean                                       0.150316       0.678797   \n",
       "std                                        0.753774       0.466991   \n",
       "min                                        0.000000       0.000000   \n",
       "25%                                        0.000000       0.000000   \n",
       "50%                                        0.000000       1.000000   \n",
       "75%                                        0.000000       1.000000   \n",
       "max                                       12.000000       1.000000   \n",
       "\n",
       "       parental_higher_education  parental_professional_occupation  \\\n",
       "count                4424.000000                       4424.000000   \n",
       "mean                    0.182640                          0.260850   \n",
       "std                     0.386415                          0.439148   \n",
       "min                     0.000000                          0.000000   \n",
       "25%                     0.000000                          0.000000   \n",
       "50%                     0.000000                          0.000000   \n",
       "75%                     0.000000                          1.000000   \n",
       "max                     1.000000                          1.000000   \n",
       "\n",
       "       application_mode_withdrawal_rate  course_withdrawal_rate  \\\n",
       "count                       4424.000000             4424.000000   \n",
       "mean                           0.321203                0.321203   \n",
       "std                            0.140266                0.121256   \n",
       "min                            0.000000                0.154047   \n",
       "25%                            0.201991                0.183099   \n",
       "50%                            0.293578                0.330233   \n",
       "75%                            0.368590                0.381395   \n",
       "max                            1.000000                0.666667   \n",
       "\n",
       "       previous_qualification_withdrawal_rate  \n",
       "count                             4424.000000  \n",
       "mean                                 0.321203  \n",
       "std                                  0.099940  \n",
       "min                                  0.166667  \n",
       "25%                                  0.290019  \n",
       "50%                                  0.290019  \n",
       "75%                                  0.290019  \n",
       "max                                  1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_categorical_withdrawal_rate(df, cat_col, target_col='target_binary'):\n",
    "    \"\"\"\n",
    "    Replace categorical column with withdrawal rate encoding.\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    cat_col: name of categorical column to encode\n",
    "    target_col: name of target column where 0=withdrawn\n",
    "    \n",
    "    Returns:\n",
    "    pandas DataFrame with categorical column replaced by withdrawal_rate\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    # Calculate withdrawal rate for each category\n",
    "    withdrawal_rates = (df[target_col] == 0).groupby(df[cat_col]).mean()\n",
    "    \n",
    "    # Create new withdrawal rate column\n",
    "    new_col_name = f'{cat_col.lower().replace(\" \", \"_\")}_withdrawal_rate'\n",
    "    df_encoded[new_col_name] = df[cat_col].map(withdrawal_rates)\n",
    "    \n",
    "    # Remove original column\n",
    "    df_encoded = df_encoded.drop(columns=[cat_col])\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "# Usage:\n",
    "df_dataset = encode_categorical_withdrawal_rate(df_dataset, 'application_mode')\n",
    "df_dataset = encode_categorical_withdrawal_rate(df_dataset, 'course')\n",
    "df_dataset = encode_categorical_withdrawal_rate(df_dataset, 'previous_qualification')\n",
    "df_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0ad428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features to encode: ['marital_status', 'application_order', 'gender', 'scholarship_holder', 'tuition_fees_up_to_date', 'debtor']\n",
      "Shape before encoding: (4424, 21)\n",
      "Shape after encoding: (4424, 31)\n",
      "Features added: 10\n",
      "New encoded features: ['marital_status_2', 'marital_status_3', 'marital_status_4', 'marital_status_5', 'marital_status_6', 'application_order_1', 'application_order_2', 'application_order_3', 'application_order_4', 'application_order_5', 'application_order_6', 'application_order_9', 'gender_1', 'scholarship_holder_1', 'tuition_fees_up_to_date_1', 'debtor_1']\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode_features(df, categorical_columns):\n",
    "    \"\"\"\n",
    "    One-hot encode specified categorical columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    categorical_columns: list of column names to encode\n",
    "    \n",
    "    Returns:\n",
    "    pandas DataFrame with categorical columns one-hot encoded\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Check which features actually exist in the dataset\n",
    "    existing_categorical = [col for col in categorical_columns if col in df.columns]\n",
    "    missing_categorical = [col for col in categorical_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_categorical:\n",
    "        print(f\"Warning: These columns not found in dataset: {missing_categorical}\")\n",
    "    \n",
    "    print(f\"Categorical features to encode: {existing_categorical}\")\n",
    "    \n",
    "    # One-hot encode with drop_first=True to avoid multicollinearity\n",
    "    df_encoded = pd.get_dummies(df, \n",
    "                               columns=existing_categorical, \n",
    "                               drop_first=True, \n",
    "                               dtype=int)\n",
    "    \n",
    "    print(f\"Shape before encoding: {df.shape}\")\n",
    "    print(f\"Shape after encoding: {df_encoded.shape}\")\n",
    "    print(f\"Features added: {df_encoded.shape[1] - df.shape[1]}\")\n",
    "    \n",
    "    # Show new encoded column names\n",
    "    new_columns = [col for col in df_encoded.columns if any(cat in col for cat in existing_categorical)]\n",
    "    print(f\"New encoded features: {new_columns}\")\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "# Usage:\n",
    "remaining_categorical = [\n",
    "    'marital_status',\n",
    "    'application_order',  \n",
    "    'gender',\n",
    "    'scholarship_holder',\n",
    "    'tuition_fees_up_to_date',\n",
    "    'debtor'\n",
    "]\n",
    "\n",
    "df_dataset = one_hot_encode_features(df_dataset, remaining_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c7412",
   "metadata": {},
   "source": [
    "# 3. Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fd789",
   "metadata": {},
   "source": [
    "## 3.A Summary\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**Logistic Regression Processing Pipeline Summary**</span>\n",
    "\n",
    "This section implemented a modular processing pipeline for logistic regression, separating train/test splitting and feature scaling into distinct functions to prevent data leakage and ensure proper workflow.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**1. Two-Function Design**</span>\n",
    "\n",
    "**Modular approach** improved maintainability:\n",
    "- `create_train_test_split_logistic()` - handles stratified 80/20 data splitting\n",
    "- `scale_features_logistic()` - applies configurable feature scaling\n",
    "\n",
    "**Benefits**: **Single responsibility principle** ensures each function performs one task, **reusable components** work with different configurations, **flexible parameters** enable easy adjustments.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**2. Critical Workflow Order**</span>\n",
    "\n",
    "**Split first, scale second** prevents **data leakage**. **Data leakage** occurs when test set information influences preprocessing, creating artificially optimistic performance estimates.\n",
    "\n",
    "**Correct sequence:**\n",
    "1. Split data (training/test)\n",
    "2. Fit scaler on training data only  \n",
    "3. Apply same scaler to test data\n",
    "\n",
    "**Why this matters**: Scaling before splitting would use test set statistics, compromising model evaluation reliability.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**3. Results Achieved**</span>\n",
    "\n",
    "**Perfect stratification**: Both training (3,539 samples) and test (885 samples) maintain identical 67.9%/32.1% class distributions.\n",
    "\n",
    "**Configurable scaling** via `scaler_type` parameter enables easy comparison testing between `standard`, `minmax`, and `none` options. **StandardScaler preferred for logistic regression** because linear models like logistic regression initialise weights to 0 or small random values, making standardised features (mean=0, std=1) easier to learn. StandardScaler is particularly important when using regularisation, as it ensures fair penalty application across all features, preventing features with larger scales from dominating the model coefficients.\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**Pipeline Outcome**</span>\n",
    "\n",
    "The pipeline produces **deployment-ready data** (X_train_scaled, X_test_scaled, y_train, y_test, scaler) whilst preventing data leakage and ensuring reliable model evaluation. **Modular design** enables easy debugging and configuration adjustments for optimal logistic regression performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd04b5a",
   "metadata": {},
   "source": [
    "## 3.B Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a31dbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 3539 samples (80%)\n",
      "Test set: 885 samples (20%)\n",
      "Training class distribution: {1: 0.679, 0: 0.321}\n",
      "Test class distribution: {1: 0.679, 0: 0.321}\n"
     ]
    }
   ],
   "source": [
    "def create_train_test_split_logistic(X_features, df_dataset, logistic_config):\n",
    "    \"\"\"\n",
    "    Create stratified train/test split for logistic regression.\n",
    "    \n",
    "    Parameters:\n",
    "    X_features: Feature matrix (unscaled)\n",
    "    df_dataset: DataFrame containing target variable\n",
    "    logistic_config: Logistic regression configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    tuple: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define target variable y\n",
    "    y = df_dataset['target_binary']\n",
    "\n",
    "    # Get required parameters with defaults\n",
    "    train_size = logistic_config.get('train_size', 0.8)\n",
    "    use_stratify = logistic_config.get('stratify', True)\n",
    "\n",
    "    # Validate parameter values\n",
    "    if not 0 < train_size < 1:\n",
    "        raise ValueError(f'train_size must be between 0 and 1, got {train_size}')\n",
    "\n",
    "    if not isinstance(use_stratify, bool):\n",
    "        raise ValueError(f'stratify must be true or false, got {use_stratify}')\n",
    "\n",
    "    # Set stratify parameter\n",
    "    stratify_param = y if use_stratify else None\n",
    "\n",
    "    # Perform train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_features,\n",
    "        y,\n",
    "        train_size=train_size,\n",
    "        random_state=42,\n",
    "        stratify=stratify_param\n",
    "    )\n",
    "\n",
    "    # Print split information\n",
    "    print(f'Training set: {len(X_train)} samples ({train_size*100:.0f}%)')\n",
    "    print(f'Test set: {len(X_test)} samples ({(1-train_size)*100:.0f}%)')\n",
    "\n",
    "    if use_stratify:\n",
    "        print(f'Training class distribution: {y_train.value_counts(normalize=True).round(3).to_dict()}')\n",
    "        print(f'Test class distribution: {y_test.value_counts(normalize=True).round(3).to_dict()}')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "logistic_config = config.get('logistic_regression_model')\n",
    "X_features = df_dataset.drop('target_binary', axis=1)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = create_train_test_split_logistic(\n",
    "    X_features, df_dataset, logistic_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb2c1b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling method applied: standard\n"
     ]
    }
   ],
   "source": [
    "def scale_features_logistic(X_train, X_test, logistic_config):\n",
    "    \"\"\"\n",
    "    Scale features using specified scaling method.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train: Training feature matrix\n",
    "    X_test: Test feature matrix\n",
    "    logistic_config: Logistic regression configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    tuple: X_train_scaled, X_test_scaled, scaler\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get scaling method\n",
    "    scaler_type = logistic_config.get('scaler_type', 'standard')\n",
    "    \n",
    "    # Validate scaler type\n",
    "    if scaler_type not in ['standard', 'minmax', 'none']:\n",
    "        raise ValueError(f'scaler_type must be \"standard\", \"minmax\", or \"none\", got {scaler_type}')\n",
    "\n",
    "    # Create scaler\n",
    "    if scaler_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    else:  # scaler_type == 'none'\n",
    "        scaler = None\n",
    "\n",
    "    # Apply scaling\n",
    "    if scaler is not None:\n",
    "        # Fit scaler on training data only\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        # Apply same scaler to test data (no re-fitting)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train_scaled = X_train\n",
    "        X_test_scaled = X_test\n",
    "\n",
    "    print(f'Scaling method applied: {scaler_type}')\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "# Scale the features\n",
    "X_train_scaled, X_test_scaled, scaler = scale_features_logistic(\n",
    "    X_train, X_test, logistic_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7030c6",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
