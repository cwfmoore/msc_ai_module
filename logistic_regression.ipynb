{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f45e2fe",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562ef62b",
   "metadata": {},
   "source": [
    "## 1.A Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd03baeb",
   "metadata": {},
   "source": [
    "## 1.B Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "653eb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STANDARD LIBRARY ===\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime as dt, timezone as tz\n",
    "\n",
    "# === THIRD‑PARTY LIBRARIES ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# === PROJECT UTILITIES ===\n",
    "from tools import Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b6995",
   "metadata": {},
   "source": [
    "## 1.C Invoke Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "84d5d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = Tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ff9f9",
   "metadata": {},
   "source": [
    "## 1.D Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "51c3f94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:54:58</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">SUCCESS!</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Loaded configuration </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NUMBER OF KEYS</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> \u001b[1m[\u001b[0m\u001b[1;92m21:54:58\u001b[0m\u001b[1m]\u001b[0m \u001b[1;32mSUCCESS!\u001b[0m\u001b[1;37m: \u001b[0m\u001b[1;33mLoaded configuration \u001b[0m\u001b[1;35mNUMBER OF KEYS\u001b[0m\u001b[1;33m: \u001b[0m\u001b[1;36m7\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = tools.load_toml_file(\"config.toml\")\n",
    "tools.print_message('success', 'Loaded configuration', format_dict={'number of keys': len(config)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08fc02",
   "metadata": {},
   "source": [
    "## 1.E Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "02026257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marital_status</th>\n",
       "      <th>application_mode</th>\n",
       "      <th>application_order</th>\n",
       "      <th>course</th>\n",
       "      <th>daytime_evening_attendance</th>\n",
       "      <th>previous_qualification</th>\n",
       "      <th>previous_qualification_grade</th>\n",
       "      <th>nationality</th>\n",
       "      <th>mothers_qualification</th>\n",
       "      <th>fathers_qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>curricular_units_2nd_sem_credited</th>\n",
       "      <th>curricular_units_2nd_sem_enrolled</th>\n",
       "      <th>curricular_units_2nd_sem_evaluations</th>\n",
       "      <th>curricular_units_2nd_sem_approved</th>\n",
       "      <th>curricular_units_2nd_sem_grade</th>\n",
       "      <th>curricular_units_2nd_sem_without_evaluations</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>inflation_rate</th>\n",
       "      <th>gdp</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   marital_status  application_mode  application_order  course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "\n",
       "   daytime_evening_attendance  previous_qualification  \\\n",
       "0                           1                       1   \n",
       "1                           1                       1   \n",
       "2                           1                       1   \n",
       "3                           1                       1   \n",
       "4                           0                       1   \n",
       "\n",
       "   previous_qualification_grade  nationality  mothers_qualification  \\\n",
       "0                         122.0            1                     19   \n",
       "1                         160.0            1                      1   \n",
       "2                         122.0            1                     37   \n",
       "3                         122.0            1                     38   \n",
       "4                         100.0            1                     37   \n",
       "\n",
       "   fathers_qualification  ...  curricular_units_2nd_sem_credited  \\\n",
       "0                     12  ...                                  0   \n",
       "1                      3  ...                                  0   \n",
       "2                     37  ...                                  0   \n",
       "3                     37  ...                                  0   \n",
       "4                     38  ...                                  0   \n",
       "\n",
       "   curricular_units_2nd_sem_enrolled  curricular_units_2nd_sem_evaluations  \\\n",
       "0                                  0                                     0   \n",
       "1                                  6                                     6   \n",
       "2                                  6                                     0   \n",
       "3                                  6                                    10   \n",
       "4                                  6                                     6   \n",
       "\n",
       "   curricular_units_2nd_sem_approved  curricular_units_2nd_sem_grade  \\\n",
       "0                                  0                        0.000000   \n",
       "1                                  6                       13.666667   \n",
       "2                                  0                        0.000000   \n",
       "3                                  5                       12.400000   \n",
       "4                                  6                       13.000000   \n",
       "\n",
       "   curricular_units_2nd_sem_without_evaluations  unemployment_rate  \\\n",
       "0                                             0               10.8   \n",
       "1                                             0               13.9   \n",
       "2                                             0               10.8   \n",
       "3                                             0                9.4   \n",
       "4                                             0               13.9   \n",
       "\n",
       "   inflation_rate   gdp    target  \n",
       "0             1.4  1.74   Dropout  \n",
       "1            -0.3  0.79  Graduate  \n",
       "2             1.4  1.74   Dropout  \n",
       "3            -0.8 -3.12  Graduate  \n",
       "4            -0.3  0.79  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open dataset\n",
    "# Realinho, V., Martins, M.V., Machado, J. and Baptista, L.M.T., 2021. Predict Students' Dropout and Academic Success. UCI Machine Learning Repository. Available at: https://doi.org/10.24432/C5MC89 [Accessed 31 May 2025].\n",
    "df_dataset = tools.load_dataset(file_name='dataset_raw.csv')\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d60678",
   "metadata": {},
   "source": [
    "## 1.F Apply Target Binary Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fb179a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_binary\n",
       "1    3003\n",
       "0    1421\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new target column with renamed values for one vs rest classification\n",
    "df_dataset['target_binary'] = df_dataset['target'].map({'Dropout': 0, 'Graduate': 1, 'Enrolled': 1})\n",
    "df_dataset['target_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2cc8f",
   "metadata": {},
   "source": [
    "## 1.G Data Shape Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "22c0669c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:54:58</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">SUCCESS!</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Dataset loaded </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ROWS</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4424</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">, </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">COLUMNS</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> \u001b[1m[\u001b[0m\u001b[1;92m21:54:58\u001b[0m\u001b[1m]\u001b[0m \u001b[1;32mSUCCESS!\u001b[0m\u001b[1;37m: \u001b[0m\u001b[1;33mDataset loaded \u001b[0m\u001b[1;35mROWS\u001b[0m\u001b[1;33m: \u001b[0m\u001b[1;36m4424\u001b[0m\u001b[1;33m, \u001b[0m\u001b[1;35mCOLUMNS\u001b[0m\u001b[1;33m: \u001b[0m\u001b[1;36m38\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shape = df_dataset.shape\n",
    "tools.print_message('success', 'Dataset loaded', format_dict={'rows': shape[0], 'columns': shape[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f0556",
   "metadata": {},
   "source": [
    "## 1.H Create Directory to Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4bbf5303",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = os.path.join(os.getcwd(), 'models')\n",
    "models_performance = os.path.join(os.getcwd(), 'models_performance')\n",
    "dirs_to_create = [models_dir, models_performance]\n",
    "for d in dirs_to_create:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fbab1e",
   "metadata": {},
   "source": [
    "# 2. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e4502",
   "metadata": {},
   "source": [
    "## 2.A Summary\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**Feature Selection for Logistic Regression**</span>\n",
    "\n",
    "This analysis prepared the dataset for Logistic Regression by removing problematic features and encoding categorical variables to create stable, interpretable predictors suitable for linear classification.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**1. Feature Removal Strategy**</span>\n",
    "\n",
    "**Removed 13 features** from original 36:\n",
    "- **Data leakage**: 5 second semester features (students who withdraw early show zeros)\n",
    "- **Severely imbalanced**: Nationality, educational special needs, international status (>97% in one category)\n",
    "- **Zero information**: Daytime/evening attendance, displaced status\n",
    "- **Weak predictors**: Economic indicators, previous qualification grade (correlation <0.10)\n",
    "\n",
    "**Result**: 23 meaningful features suitable for linear classification.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**2. High Cardinality Feature Engineering**</span>\n",
    "\n",
    "**Parents' qualifications and occupations** (150+ total categories) were reduced to **2 binary indicators**:\n",
    "- `parental_higher_education` - at least one parent with higher education\n",
    "- `parental_professional_occupation` - at least one parent in professional role\n",
    "\n",
    "**Benefits**: Captures family background whilst avoiding **coefficient inflation** from too many categories.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**3. Withdrawal Rate Encoding**</span>\n",
    "\n",
    "**Medium cardinality features** were replaced with their historical withdrawal rates:\n",
    "- `application_mode` (18 categories) → `application_mode_withdrawal_rate`\n",
    "- `course` (17 categories) → `course_withdrawal_rate` \n",
    "- `previous_qualification` (17 categories) → `previous_qualification_withdrawal_rate`\n",
    "\n",
    "**Advantage**: Creates continuous predictors where higher values = higher risk, avoiding **sparse matrices** that harm model convergence.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**4. One-Hot Encoding**</span>\n",
    "\n",
    "**Low cardinality features** (2-8 categories) used **one-hot encoding** with `drop_first=True`:\n",
    "- Marital status, application order, gender, scholarship holder, tuition fees status, debtor status\n",
    "- Creates ~15 binary features\n",
    "- **Drop-first prevents multicollinearity** - avoids perfect correlation between category indicators\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**Impact on Logistic Regression**</span>\n",
    "\n",
    "**Model stability**: Strategic encoding prevents **multicollinearity** and **overfitting** whilst maintaining interpretable coefficients. **Early intervention capability**: Uses only first semester data for timely withdrawal prediction. **Regularisation ready**: 25 well-encoded features work effectively with **L1/L2 regularisation** techniques.\n",
    "\n",
    "This feature selection balances predictive power with model stability, creating optimal conditions for Logistic Regression deployment in student retention systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a7235",
   "metadata": {},
   "source": [
    "## 2.B Features to Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cfb1a903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt;&gt;&gt; <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:54:58</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">SUCCESS!</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Dropped features </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NUMBER OF FEATURES</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       ">>> \u001b[1m[\u001b[0m\u001b[1;92m21:54:58\u001b[0m\u001b[1m]\u001b[0m \u001b[1;32mSUCCESS!\u001b[0m\u001b[1;37m: \u001b[0m\u001b[1;33mDropped features \u001b[0m\u001b[1;35mNUMBER OF FEATURES\u001b[0m\u001b[1;33m: \u001b[0m\u001b[1;36m15\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data leakage - 2nd semester features\n",
    "data_leakage_features = [\n",
    "    'curricular_units_2nd_sem_credited',\n",
    "    'curricular_units_2nd_sem_enrolled', \n",
    "    'curricular_units_2nd_sem_evaluations',\n",
    "    'curricular_units_2nd_sem_approved',\n",
    "    'curricular_units_2nd_sem_grade'\n",
    "]\n",
    "\n",
    "# Severely imbalanced features (>97% in one category)\n",
    "imbalanced_features = [\n",
    "    'nationality',\n",
    "    'educational_special_needs',\n",
    "    'international'\n",
    "]\n",
    "\n",
    "# Zero information value features\n",
    "zero_info_features = [\n",
    "    'daytime_evening_attendance',\n",
    "    'displaced'\n",
    "]\n",
    "\n",
    "# Weak predictors (correlation < 0.10)\n",
    "weak_predictors = [\n",
    "    'unemployment_rate',\n",
    "    'inflation_rate',\n",
    "    'gdp',\n",
    "    'previous_qualification_grade'\n",
    "]\n",
    "\n",
    "# Old target column\n",
    "target_column = ['target']\n",
    "\n",
    "# Combine all features to drop\n",
    "features_to_drop = (data_leakage_features + \n",
    "                   imbalanced_features + \n",
    "                   zero_info_features + \n",
    "                   weak_predictors + \n",
    "                   target_column)\n",
    "\n",
    "df_dataset.drop(columns=features_to_drop, inplace=True, errors='ignore')\n",
    "tools.print_message('success', 'Dropped features', format_dict={'number of features': len(features_to_drop)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5492efe3",
   "metadata": {},
   "source": [
    "## 2.C Reduce High Cardinality Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d1340ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining parental features: ['mothers_qualification', 'fathers_qualification', 'mothers_occupation', 'fathers_occupation']\n"
     ]
    }
   ],
   "source": [
    "# Check if parental features still exist in dataset\n",
    "parental_features = ['mothers_qualification', 'fathers_qualification', 'mothers_occupation', 'fathers_occupation']\n",
    "existing_features = [f for f in parental_features if f in df_dataset.columns]\n",
    "print(f\"Remaining parental features: {existing_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6718c901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parental_higher_education\n",
       "0    3616\n",
       "1     808\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To reduce the number of categories in the parental qualification and occupation features, we will group them into broader categories.\n",
    "def create_parental_higher_ed(df):\n",
    "    \"\"\"\n",
    "    Creates binary indicator for parental higher education.\n",
    "    Returns 1 if at least one parent has higher education, 0 otherwise.\n",
    "    \"\"\"\n",
    "    higher_ed_codes = [2, 3, 4, 5, 6, 39, 40, 41, 42, 43, 44]\n",
    "    \n",
    "    mother_higher_ed = df['mothers_qualification'].isin(higher_ed_codes)\n",
    "    father_higher_ed = df['fathers_qualification'].isin(higher_ed_codes)\n",
    "    \n",
    "    # At least one parent has higher education\n",
    "    df['parental_higher_education'] = (mother_higher_ed | father_higher_ed).astype(int)\n",
    "    df = df.drop(columns=['mothers_qualification', 'fathers_qualification'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage:\n",
    "df_dataset = create_parental_higher_ed(df_dataset)\n",
    "df_dataset.parental_higher_education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d6ba6264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parental_professional_occupation\n",
       "0    3270\n",
       "1    1154\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_parental_professional_occupation(df):\n",
    "    \"\"\"\n",
    "    Creates binary indicator for parental professional occupation.\n",
    "    Returns 1 if at least one parent has professional/managerial role, 0 otherwise.\n",
    "    \"\"\"\n",
    "    professional_codes = [1, 2, 3, 101, 102, 112, 114, 121, 122, 123, 124, \n",
    "                          131, 132, 134, 135]\n",
    "    \n",
    "    mother_professional = df['mothers_occupation'].isin(professional_codes)\n",
    "    father_professional = df['fathers_occupation'].isin(professional_codes)\n",
    "    \n",
    "    # At least one parent has professional occupation\n",
    "    df['parental_professional_occupation'] = (mother_professional | father_professional).astype(int)\n",
    "    df = df.drop(columns=['mothers_occupation', 'fathers_occupation'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage:\n",
    "df_dataset = create_parental_professional_occupation(df_dataset)\n",
    "df_dataset.parental_professional_occupation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fd7b134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after parental feature engineering: (4424, 21)\n",
      "Remaining features: ['marital_status', 'application_mode', 'application_order', 'course', 'previous_qualification', 'admission_grade', 'debtor', 'tuition_fees_up_to_date', 'gender', 'scholarship_holder', 'age_at_enrollment', 'curricular_units_1st_sem_credited', 'curricular_units_1st_sem_enrolled', 'curricular_units_1st_sem_evaluations', 'curricular_units_1st_sem_approved', 'curricular_units_1st_sem_grade', 'curricular_units_1st_sem_without_evaluations', 'curricular_units_2nd_sem_without_evaluations', 'target_binary', 'parental_higher_education', 'parental_professional_occupation']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset shape after parental feature engineering: {df_dataset.shape}\")\n",
    "print(f\"Remaining features: {df_dataset.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5f399c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marital_status</th>\n",
       "      <th>application_order</th>\n",
       "      <th>admission_grade</th>\n",
       "      <th>debtor</th>\n",
       "      <th>tuition_fees_up_to_date</th>\n",
       "      <th>gender</th>\n",
       "      <th>scholarship_holder</th>\n",
       "      <th>age_at_enrollment</th>\n",
       "      <th>curricular_units_1st_sem_credited</th>\n",
       "      <th>curricular_units_1st_sem_enrolled</th>\n",
       "      <th>...</th>\n",
       "      <th>curricular_units_1st_sem_approved</th>\n",
       "      <th>curricular_units_1st_sem_grade</th>\n",
       "      <th>curricular_units_1st_sem_without_evaluations</th>\n",
       "      <th>curricular_units_2nd_sem_without_evaluations</th>\n",
       "      <th>target_binary</th>\n",
       "      <th>parental_higher_education</th>\n",
       "      <th>parental_professional_occupation</th>\n",
       "      <th>application_mode_withdrawal_rate</th>\n",
       "      <th>course_withdrawal_rate</th>\n",
       "      <th>previous_qualification_withdrawal_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>4424.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.178571</td>\n",
       "      <td>1.727848</td>\n",
       "      <td>126.978119</td>\n",
       "      <td>0.113698</td>\n",
       "      <td>0.880651</td>\n",
       "      <td>0.351718</td>\n",
       "      <td>0.248418</td>\n",
       "      <td>23.265145</td>\n",
       "      <td>0.709991</td>\n",
       "      <td>6.270570</td>\n",
       "      <td>...</td>\n",
       "      <td>4.706600</td>\n",
       "      <td>10.640822</td>\n",
       "      <td>0.137658</td>\n",
       "      <td>0.150316</td>\n",
       "      <td>0.678797</td>\n",
       "      <td>0.182640</td>\n",
       "      <td>0.260850</td>\n",
       "      <td>0.321203</td>\n",
       "      <td>0.321203</td>\n",
       "      <td>0.321203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.605747</td>\n",
       "      <td>1.313793</td>\n",
       "      <td>14.482001</td>\n",
       "      <td>0.317480</td>\n",
       "      <td>0.324235</td>\n",
       "      <td>0.477560</td>\n",
       "      <td>0.432144</td>\n",
       "      <td>7.587816</td>\n",
       "      <td>2.360507</td>\n",
       "      <td>2.480178</td>\n",
       "      <td>...</td>\n",
       "      <td>3.094238</td>\n",
       "      <td>4.843663</td>\n",
       "      <td>0.690880</td>\n",
       "      <td>0.753774</td>\n",
       "      <td>0.466991</td>\n",
       "      <td>0.386415</td>\n",
       "      <td>0.439148</td>\n",
       "      <td>0.140266</td>\n",
       "      <td>0.121256</td>\n",
       "      <td>0.099940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154047</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>117.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201991</td>\n",
       "      <td>0.183099</td>\n",
       "      <td>0.290019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293578</td>\n",
       "      <td>0.330233</td>\n",
       "      <td>0.290019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>134.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.381395</td>\n",
       "      <td>0.290019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       marital_status  application_order  admission_grade       debtor  \\\n",
       "count     4424.000000        4424.000000      4424.000000  4424.000000   \n",
       "mean         1.178571           1.727848       126.978119     0.113698   \n",
       "std          0.605747           1.313793        14.482001     0.317480   \n",
       "min          1.000000           0.000000        95.000000     0.000000   \n",
       "25%          1.000000           1.000000       117.900000     0.000000   \n",
       "50%          1.000000           1.000000       126.100000     0.000000   \n",
       "75%          1.000000           2.000000       134.800000     0.000000   \n",
       "max          6.000000           9.000000       190.000000     1.000000   \n",
       "\n",
       "       tuition_fees_up_to_date       gender  scholarship_holder  \\\n",
       "count              4424.000000  4424.000000         4424.000000   \n",
       "mean                  0.880651     0.351718            0.248418   \n",
       "std                   0.324235     0.477560            0.432144   \n",
       "min                   0.000000     0.000000            0.000000   \n",
       "25%                   1.000000     0.000000            0.000000   \n",
       "50%                   1.000000     0.000000            0.000000   \n",
       "75%                   1.000000     1.000000            0.000000   \n",
       "max                   1.000000     1.000000            1.000000   \n",
       "\n",
       "       age_at_enrollment  curricular_units_1st_sem_credited  \\\n",
       "count        4424.000000                        4424.000000   \n",
       "mean           23.265145                           0.709991   \n",
       "std             7.587816                           2.360507   \n",
       "min            17.000000                           0.000000   \n",
       "25%            19.000000                           0.000000   \n",
       "50%            20.000000                           0.000000   \n",
       "75%            25.000000                           0.000000   \n",
       "max            70.000000                          20.000000   \n",
       "\n",
       "       curricular_units_1st_sem_enrolled  ...  \\\n",
       "count                        4424.000000  ...   \n",
       "mean                            6.270570  ...   \n",
       "std                             2.480178  ...   \n",
       "min                             0.000000  ...   \n",
       "25%                             5.000000  ...   \n",
       "50%                             6.000000  ...   \n",
       "75%                             7.000000  ...   \n",
       "max                            26.000000  ...   \n",
       "\n",
       "       curricular_units_1st_sem_approved  curricular_units_1st_sem_grade  \\\n",
       "count                        4424.000000                     4424.000000   \n",
       "mean                            4.706600                       10.640822   \n",
       "std                             3.094238                        4.843663   \n",
       "min                             0.000000                        0.000000   \n",
       "25%                             3.000000                       11.000000   \n",
       "50%                             5.000000                       12.285714   \n",
       "75%                             6.000000                       13.400000   \n",
       "max                            26.000000                       18.875000   \n",
       "\n",
       "       curricular_units_1st_sem_without_evaluations  \\\n",
       "count                                   4424.000000   \n",
       "mean                                       0.137658   \n",
       "std                                        0.690880   \n",
       "min                                        0.000000   \n",
       "25%                                        0.000000   \n",
       "50%                                        0.000000   \n",
       "75%                                        0.000000   \n",
       "max                                       12.000000   \n",
       "\n",
       "       curricular_units_2nd_sem_without_evaluations  target_binary  \\\n",
       "count                                   4424.000000    4424.000000   \n",
       "mean                                       0.150316       0.678797   \n",
       "std                                        0.753774       0.466991   \n",
       "min                                        0.000000       0.000000   \n",
       "25%                                        0.000000       0.000000   \n",
       "50%                                        0.000000       1.000000   \n",
       "75%                                        0.000000       1.000000   \n",
       "max                                       12.000000       1.000000   \n",
       "\n",
       "       parental_higher_education  parental_professional_occupation  \\\n",
       "count                4424.000000                       4424.000000   \n",
       "mean                    0.182640                          0.260850   \n",
       "std                     0.386415                          0.439148   \n",
       "min                     0.000000                          0.000000   \n",
       "25%                     0.000000                          0.000000   \n",
       "50%                     0.000000                          0.000000   \n",
       "75%                     0.000000                          1.000000   \n",
       "max                     1.000000                          1.000000   \n",
       "\n",
       "       application_mode_withdrawal_rate  course_withdrawal_rate  \\\n",
       "count                       4424.000000             4424.000000   \n",
       "mean                           0.321203                0.321203   \n",
       "std                            0.140266                0.121256   \n",
       "min                            0.000000                0.154047   \n",
       "25%                            0.201991                0.183099   \n",
       "50%                            0.293578                0.330233   \n",
       "75%                            0.368590                0.381395   \n",
       "max                            1.000000                0.666667   \n",
       "\n",
       "       previous_qualification_withdrawal_rate  \n",
       "count                             4424.000000  \n",
       "mean                                 0.321203  \n",
       "std                                  0.099940  \n",
       "min                                  0.166667  \n",
       "25%                                  0.290019  \n",
       "50%                                  0.290019  \n",
       "75%                                  0.290019  \n",
       "max                                  1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_categorical_withdrawal_rate(df, cat_col, target_col='target_binary'):\n",
    "    \"\"\"\n",
    "    Replace categorical column with withdrawal rate encoding.\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    cat_col: name of categorical column to encode\n",
    "    target_col: name of target column where 0=withdrawn\n",
    "    \n",
    "    Returns:\n",
    "    pandas DataFrame with categorical column replaced by withdrawal_rate\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    # Calculate withdrawal rate for each category\n",
    "    withdrawal_rates = (df[target_col] == 0).groupby(df[cat_col]).mean()\n",
    "    \n",
    "    # Create new withdrawal rate column\n",
    "    new_col_name = f'{cat_col.lower().replace(\" \", \"_\")}_withdrawal_rate'\n",
    "    df_encoded[new_col_name] = df[cat_col].map(withdrawal_rates)\n",
    "    \n",
    "    # Remove original column\n",
    "    df_encoded = df_encoded.drop(columns=[cat_col])\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "# Usage:\n",
    "df_dataset = encode_categorical_withdrawal_rate(df_dataset, 'application_mode')\n",
    "df_dataset = encode_categorical_withdrawal_rate(df_dataset, 'course')\n",
    "df_dataset = encode_categorical_withdrawal_rate(df_dataset, 'previous_qualification')\n",
    "df_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b0ad428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features to encode: ['marital_status', 'application_order', 'gender', 'scholarship_holder', 'tuition_fees_up_to_date', 'debtor']\n",
      "Shape before encoding: (4424, 21)\n",
      "Shape after encoding: (4424, 31)\n",
      "Features added: 10\n",
      "New encoded features: ['marital_status_2', 'marital_status_3', 'marital_status_4', 'marital_status_5', 'marital_status_6', 'application_order_1', 'application_order_2', 'application_order_3', 'application_order_4', 'application_order_5', 'application_order_6', 'application_order_9', 'gender_1', 'scholarship_holder_1', 'tuition_fees_up_to_date_1', 'debtor_1']\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode_features(df, categorical_columns):\n",
    "    \"\"\"\n",
    "    One-hot encode specified categorical columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    categorical_columns: list of column names to encode\n",
    "    \n",
    "    Returns:\n",
    "    pandas DataFrame with categorical columns one-hot encoded\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Check which features actually exist in the dataset\n",
    "    existing_categorical = [col for col in categorical_columns if col in df.columns]\n",
    "    missing_categorical = [col for col in categorical_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_categorical:\n",
    "        print(f\"Warning: These columns not found in dataset: {missing_categorical}\")\n",
    "    \n",
    "    print(f\"Categorical features to encode: {existing_categorical}\")\n",
    "    \n",
    "    # One-hot encode with drop_first=True to avoid multicollinearity\n",
    "    df_encoded = pd.get_dummies(df, \n",
    "                               columns=existing_categorical, \n",
    "                               drop_first=True, \n",
    "                               dtype=int)\n",
    "    \n",
    "    print(f\"Shape before encoding: {df.shape}\")\n",
    "    print(f\"Shape after encoding: {df_encoded.shape}\")\n",
    "    print(f\"Features added: {df_encoded.shape[1] - df.shape[1]}\")\n",
    "    \n",
    "    # Show new encoded column names\n",
    "    new_columns = [col for col in df_encoded.columns if any(cat in col for cat in existing_categorical)]\n",
    "    print(f\"New encoded features: {new_columns}\")\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "# Usage:\n",
    "remaining_categorical = [\n",
    "    'marital_status',\n",
    "    'application_order',  \n",
    "    'gender',\n",
    "    'scholarship_holder',\n",
    "    'tuition_fees_up_to_date',\n",
    "    'debtor'\n",
    "]\n",
    "\n",
    "df_dataset = one_hot_encode_features(df_dataset, remaining_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c7412",
   "metadata": {},
   "source": [
    "# 3. Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fd789",
   "metadata": {},
   "source": [
    "## 3.A Summary\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**Logistic Regression Processing Pipeline Summary**</span>\n",
    "\n",
    "This section implemented a modular processing pipeline for logistic regression, separating train/test splitting and feature scaling into distinct functions to prevent data leakage and ensure proper workflow.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**1. Two-Function Design**</span>\n",
    "\n",
    "**Modular approach** improved maintainability:\n",
    "- `create_train_test_split_logistic()` - handles stratified 80/20 data splitting\n",
    "- `scale_features_logistic()` - applies configurable feature scaling\n",
    "\n",
    "**Benefits**: **Single responsibility principle** ensures each function performs one task, **reusable components** work with different configurations, **flexible parameters** enable easy adjustments.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**2. Critical Workflow Order**</span>\n",
    "\n",
    "**Split first, scale second** prevents **data leakage**. **Data leakage** occurs when test set information influences preprocessing, creating artificially optimistic performance estimates.\n",
    "\n",
    "**Correct sequence:**\n",
    "1. Split data (training/test)\n",
    "2. Fit scaler on training data only  \n",
    "3. Apply same scaler to test data\n",
    "\n",
    "**Why this matters**: Scaling before splitting would use test set statistics, compromising model evaluation reliability.\n",
    "\n",
    "### <span style=\"color: #2E86AB;\">**3. Results Achieved**</span>\n",
    "\n",
    "**Perfect stratification**: Both training (3,539 samples) and test (885 samples) maintain identical 67.9%/32.1% class distributions.\n",
    "\n",
    "**Configurable scaling** via `scaler_type` parameter enables easy comparison testing between `standard`, `minmax`, and `none` options. **StandardScaler preferred for logistic regression** because linear models like logistic regression initialise weights to 0 or small random values, making standardised features (mean=0, std=1) easier to learn. StandardScaler is particularly important when using regularisation, as it ensures fair penalty application across all features, preventing features with larger scales from dominating the model coefficients.\n",
    "\n",
    "### <span style=\"color: #e74c3c;\">**Pipeline Outcome**</span>\n",
    "\n",
    "The pipeline produces **deployment-ready data** (X_train_scaled, X_test_scaled, y_train, y_test, scaler) whilst preventing data leakage and ensuring reliable model evaluation. **Modular design** enables easy debugging and configuration adjustments for optimal logistic regression performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd04b5a",
   "metadata": {},
   "source": [
    "## 3.B Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7a31dbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 3539 samples (80%)\n",
      "Test set: 885 samples (20%)\n",
      "Training class distribution: {1: 0.679, 0: 0.321}\n",
      "Test class distribution: {1: 0.679, 0: 0.321}\n"
     ]
    }
   ],
   "source": [
    "def create_train_test_split_logistic(X_features, df_dataset, logistic_config):\n",
    "    \"\"\"\n",
    "    Create stratified train/test split for logistic regression.\n",
    "    \n",
    "    Parameters:\n",
    "    X_features: Feature matrix (unscaled)\n",
    "    df_dataset: DataFrame containing target variable\n",
    "    logistic_config: Logistic regression configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    tuple: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define target variable y\n",
    "    y = df_dataset['target_binary']\n",
    "\n",
    "    # Get required parameters with defaults\n",
    "    train_size = logistic_config.get('train_size', 0.8)\n",
    "    use_stratify = logistic_config.get('stratify', True)\n",
    "\n",
    "    # Validate parameter values\n",
    "    if not 0 < train_size < 1:\n",
    "        raise ValueError(f'train_size must be between 0 and 1, got {train_size}')\n",
    "\n",
    "    if not isinstance(use_stratify, bool):\n",
    "        raise ValueError(f'stratify must be true or false, got {use_stratify}')\n",
    "\n",
    "    # Set stratify parameter\n",
    "    stratify_param = y if use_stratify else None\n",
    "\n",
    "    # Perform train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_features,\n",
    "        y,\n",
    "        train_size=train_size,\n",
    "        random_state=42,\n",
    "        stratify=stratify_param\n",
    "    )\n",
    "\n",
    "    # Print split information\n",
    "    print(f'Training set: {len(X_train)} samples ({train_size*100:.0f}%)')\n",
    "    print(f'Test set: {len(X_test)} samples ({(1-train_size)*100:.0f}%)')\n",
    "\n",
    "    if use_stratify:\n",
    "        print(f'Training class distribution: {y_train.value_counts(normalize=True).round(3).to_dict()}')\n",
    "        print(f'Test class distribution: {y_test.value_counts(normalize=True).round(3).to_dict()}')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "logistic_config = config.get('logistic_regression_model')\n",
    "X_features = df_dataset.drop('target_binary', axis=1)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = create_train_test_split_logistic(\n",
    "    X_features, df_dataset, logistic_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fb2c1b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling method applied: standard\n"
     ]
    }
   ],
   "source": [
    "def scale_features_logistic(X_train, X_test, logistic_config):\n",
    "    \"\"\"\n",
    "    Scale features using specified scaling method.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train: Training feature matrix\n",
    "    X_test: Test feature matrix\n",
    "    logistic_config: Logistic regression configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "    tuple: X_train_scaled, X_test_scaled, scaler\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get scaling method\n",
    "    scaler_type = logistic_config.get('scaler_type', 'standard')\n",
    "    \n",
    "    # Validate scaler type\n",
    "    if scaler_type not in ['standard', 'minmax', 'none']:\n",
    "        raise ValueError(f'scaler_type must be \"standard\", \"minmax\", or \"none\", got {scaler_type}')\n",
    "\n",
    "    # Create scaler\n",
    "    if scaler_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    else:  # scaler_type == 'none'\n",
    "        scaler = None\n",
    "\n",
    "    # Apply scaling\n",
    "    if scaler is not None:\n",
    "        # Fit scaler on training data only\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        # Apply same scaler to test data (no re-fitting)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train_scaled = X_train\n",
    "        X_test_scaled = X_test\n",
    "\n",
    "    print(f'Scaling method applied: {scaler_type}')\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "# Scale the features\n",
    "X_train_scaled, X_test_scaled, scaler = scale_features_logistic(\n",
    "    X_train, X_test, logistic_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7030c6",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c62ee3",
   "metadata": {},
   "source": [
    "## 4.A Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "20e5f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_performance_to_csv(\n",
    "    model_name, \n",
    "    training_time, \n",
    "    best_cv_score, \n",
    "    best_params, \n",
    "    y_test, \n",
    "    y_pred, \n",
    "    models_performance_dir,\n",
    "    additional_metrics=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Save model performance metrics to CSV file.\n",
    "    Creates CSV if it doesn't exist, appends if it does.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_name: str, name of the model\n",
    "    - training_time: float, training time in seconds\n",
    "    - best_cv_score: float, best cross-validation F1 score\n",
    "    - best_params: dict, best hyperparameters\n",
    "    - y_test: array, true test labels\n",
    "    - y_pred: array, predicted test labels\n",
    "    - models_performance_dir: str, directory to save CSV\n",
    "    - additional_metrics: dict, any additional metrics to include\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate test set metrics\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_precision = precision_score(y_test, y_pred)\n",
    "    test_recall = recall_score(y_test, y_pred)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate specificity (True Negative Rate)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    test_specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    # Create metrics dictionary\n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'training_time_seconds': round(training_time, 2),\n",
    "        'best_cv_f1_score': round(best_cv_score, 4),\n",
    "        'test_accuracy': round(test_accuracy, 4),\n",
    "        'test_precision': round(test_precision, 4),\n",
    "        'test_recall': round(test_recall, 4),\n",
    "        'test_f1_score': round(test_f1, 4),\n",
    "        'test_specificity': round(test_specificity, 4),\n",
    "        'true_positives': int(tp),\n",
    "        'false_positives': int(fp),\n",
    "        'true_negatives': int(tn),\n",
    "        'false_negatives': int(fn),\n",
    "        'best_parameters': json.dumps(best_params)\n",
    "    }\n",
    "    \n",
    "    # Add any additional metrics\n",
    "    if additional_metrics:\n",
    "        metrics.update(additional_metrics)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    new_row = pd.DataFrame([metrics])\n",
    "    \n",
    "    # CSV file path\n",
    "    csv_path = os.path.join(models_performance_dir, 'model_performance_log.csv')\n",
    "    \n",
    "    # Check if CSV exists\n",
    "    if os.path.exists(csv_path):\n",
    "        # Append to existing CSV\n",
    "        new_row.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "        print(f\"📈 Performance metrics appended to {csv_path}\")\n",
    "    else:\n",
    "        # Create new CSV\n",
    "        new_row.to_csv(csv_path, mode='w', header=True, index=False)\n",
    "        print(f\"📊 New performance log created: {csv_path}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"✅ Logged performance for {model_name}\")\n",
    "    print(f\"   🎯 Test F1: {test_f1:.4f}\")\n",
    "    print(f\"   ⏱️  Training time: {training_time:.1f}s\")\n",
    "    print(f\"   🔍 Specificity: {test_specificity:.4f}\")\n",
    "    \n",
    "    return csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "01b1bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global class definition (put this at the top of your file)\n",
    "class LogisticRegressionNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x)).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1f779164",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_pytorch_logistic_regression_from_config(config, X_train, device='cuda', param_profile='pytorch_logistic_regression_testing'):\n",
    "    \"\"\"\n",
    "    Setup PyTorch logistic regression with parameters from config.\n",
    "    \"\"\"\n",
    "    # Get config section\n",
    "    pytorch_config = config[param_profile]\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Check GPU availability\n",
    "    if device == 'cuda' and not torch.cuda.is_available():\n",
    "        print(\"⚠️ CUDA not available, using CPU\")\n",
    "        device = 'cpu'\n",
    "    else:\n",
    "        print(f\"✅ Using device: {device}\")\n",
    "        if device == 'cuda':\n",
    "            print(f\"🚀 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Create skorch model\n",
    "    model = NeuralNetClassifier(\n",
    "        LogisticRegressionNet,\n",
    "        module__input_dim=input_dim,\n",
    "        criterion=nn.BCELoss,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        lr=0.01,  # Will be tuned by grid search\n",
    "        max_epochs=50,  # Will be tuned by grid search\n",
    "        batch_size=32,  # Will be tuned by grid search\n",
    "        device=device,\n",
    "        train_split=None,  # Don't split training data\n",
    "        verbose=0,\n",
    "    )\n",
    "    \n",
    "    # Build parameter grid from config\n",
    "    param_grid = {\n",
    "        'lr': pytorch_config['lr_values'],\n",
    "        'max_epochs': pytorch_config['max_epochs_values'],\n",
    "        'optimizer__weight_decay': pytorch_config['weight_decay_values'],\n",
    "        'batch_size': pytorch_config['batch_size_values']\n",
    "    }\n",
    "    \n",
    "    # Cross-validation strategy\n",
    "    cv_strategy = StratifiedKFold(\n",
    "        n_splits=pytorch_config['cv_folds'],\n",
    "        shuffle=True,\n",
    "        random_state=pytorch_config['random_state']\n",
    "    )\n",
    "    \n",
    "    # Create grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv_strategy,\n",
    "        scoring=pytorch_config['scoring_metric'],\n",
    "        n_jobs=1,  # Must be 1 for GPU training\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Model configured for {input_dim} features\")\n",
    "    print(f\"🔧 Parameter grid: {len(param_grid['lr']) * len(param_grid['max_epochs']) * len(param_grid['optimizer__weight_decay']) * len(param_grid['batch_size'])} combinations\")\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "baae3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pytorch_model_with_timestamp(grid_search, models_dir, scaler, feature_columns, logistic_config):\n",
    "    \"\"\"Save PyTorch model with complete preprocessing pipeline\"\"\"\n",
    "    utc_time = dt.now(tz=tz.utc)\n",
    "    timestamp = utc_time.strftime(\"%y%m%d-%H%M%S\")\n",
    "    f1_score = grid_search.best_score_\n",
    "    f1_formatted = f\"F1-{f1_score:.4f}\".replace(\".\", \"-\")\n",
    "    \n",
    "    # Create model name\n",
    "    model_name = f\"LR_model_{timestamp}_{f1_formatted}\"\n",
    "    \n",
    "    # Create subdirectory for this model\n",
    "    model_dir = os.path.join(models_dir, model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model weights\n",
    "    model_path = os.path.join(model_dir, f\"{model_name}.pth\")\n",
    "    torch.save(grid_search.best_estimator_.module_.state_dict(), model_path)\n",
    "    \n",
    "    # Save scaler\n",
    "    scaler_path = os.path.join(model_dir, \"scaler.pkl\")\n",
    "    with open(scaler_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    # Save feature columns order\n",
    "    features_path = os.path.join(model_dir, \"feature_columns.pkl\")\n",
    "    with open(features_path, 'wb') as f:\n",
    "        pickle.dump(feature_columns, f)\n",
    "    \n",
    "    # Save comprehensive metadata\n",
    "    metadata = {\n",
    "        'model_name': model_name,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'input_dim': grid_search.best_estimator_.module_.linear.in_features,\n",
    "        'timestamp': timestamp,\n",
    "        'f1_score': f1_score,\n",
    "        'scaler_type': logistic_config.get('scaler_type', 'standard'),\n",
    "        'num_features': len(feature_columns),\n",
    "        'feature_names': list(feature_columns)  # Store as list for JSON serialization\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(model_dir, \"metadata.json\")\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Model saved in directory: {model_name}/\")\n",
    "    print(f\"📁 Model file: {model_name}.pth\")\n",
    "    print(f\"🔧 Scaler: scaler.pkl\")\n",
    "    print(f\"📋 Features: feature_columns.pkl\")\n",
    "    print(f\"📋 Metadata: metadata.json\")\n",
    "    \n",
    "    return model_path, metadata_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "84df3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_pytorch_model(models_dir, device='cuda'):\n",
    "    \"\"\"Load PyTorch model with complete preprocessing pipeline\"\"\"\n",
    "    \n",
    "    # Find all model subdirectories\n",
    "    model_dirs = [d for d in os.listdir(models_dir) \n",
    "                  if os.path.isdir(os.path.join(models_dir, d)) \n",
    "                  and d.startswith(\"LR_model_\")]\n",
    "    \n",
    "    if not model_dirs:\n",
    "        print(\"❌ No model directories found!\")\n",
    "        return None\n",
    "    \n",
    "    # Find best F1 score across all models\n",
    "    best_f1 = 0\n",
    "    best_metadata = None\n",
    "    best_model_dir = None\n",
    "    \n",
    "    for model_dir_name in model_dirs:\n",
    "        metadata_path = os.path.join(models_dir, model_dir_name, \"metadata.json\")\n",
    "        \n",
    "        if os.path.exists(metadata_path):\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "                if metadata['f1_score'] > best_f1:\n",
    "                    best_f1 = metadata['f1_score']\n",
    "                    best_metadata = metadata\n",
    "                    best_model_dir = model_dir_name\n",
    "    \n",
    "    if best_metadata is None:\n",
    "        print(\"❌ No valid models found!\")\n",
    "        return None\n",
    "    \n",
    "    # Construct paths to best model components\n",
    "    best_dir_path = os.path.join(models_dir, best_model_dir)\n",
    "    model_file = os.path.join(best_dir_path, f\"{best_metadata['model_name']}.pth\")\n",
    "    scaler_file = os.path.join(best_dir_path, \"scaler.pkl\")\n",
    "    features_file = os.path.join(best_dir_path, \"feature_columns.pkl\")\n",
    "    \n",
    "    # Check all required files exist\n",
    "    missing_files = []\n",
    "    if not os.path.exists(model_file):\n",
    "        missing_files.append(\"model weights\")\n",
    "    if not os.path.exists(scaler_file):\n",
    "        missing_files.append(\"scaler\")\n",
    "    if not os.path.exists(features_file):\n",
    "        missing_files.append(\"feature columns\")\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"❌ Missing files: {', '.join(missing_files)}\")\n",
    "        return None\n",
    "    \n",
    "    # Load scaler (CRITICAL FIX)\n",
    "    with open(scaler_file, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    \n",
    "    # Load feature columns (CRITICAL FIX)\n",
    "    with open(features_file, 'rb') as f:\n",
    "        feature_columns = pickle.load(f)\n",
    "    \n",
    "    # Recreate the model\n",
    "    skorch_model = NeuralNetClassifier(\n",
    "        LogisticRegressionNet,\n",
    "        module__input_dim=best_metadata['input_dim'],\n",
    "        criterion=torch.nn.BCELoss,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        device=device,\n",
    "        train_split=None,\n",
    "        verbose=0,\n",
    "        **best_metadata['best_params']\n",
    "    )\n",
    "    \n",
    "    # Load the weights\n",
    "    skorch_model.initialize()\n",
    "    skorch_model.module_.load_state_dict(torch.load(model_file, map_location=device))\n",
    "    \n",
    "    print(f\"📂 Loaded model from directory: {best_model_dir}/\")\n",
    "    print(f\"🏆 F1 Score: {best_f1:.4f}\")\n",
    "    print(f\"⚙️ Parameters: {best_metadata['best_params']}\")\n",
    "    print(f\"🔧 Scaler type: {best_metadata.get('scaler_type', 'unknown')}\")\n",
    "    print(f\"📊 Features: {len(feature_columns)}\")\n",
    "    \n",
    "    return skorch_model, best_metadata, scaler, feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6abf7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_data_for_loaded_model(X_test_raw, scaler, expected_feature_columns):\n",
    "    \"\"\"\n",
    "    Apply the same preprocessing pipeline to test data that was used during training.\n",
    "    \n",
    "    Parameters:\n",
    "    X_test_raw: Raw test features (after feature engineering but before scaling)\n",
    "    scaler: Fitted scaler from training\n",
    "    expected_feature_columns: Feature column order from training\n",
    "    \n",
    "    Returns:\n",
    "    X_test_processed: Scaled and correctly ordered features ready for prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure we have a DataFrame\n",
    "    if isinstance(X_test_raw, np.ndarray):\n",
    "        print(\"❌ Test data must be DataFrame to ensure correct feature alignment\")\n",
    "        return None\n",
    "    \n",
    "    # Check feature alignment\n",
    "    missing_features = set(expected_feature_columns) - set(X_test_raw.columns)\n",
    "    extra_features = set(X_test_raw.columns) - set(expected_feature_columns)\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"❌ Missing features in test data: {missing_features}\")\n",
    "        return None\n",
    "    \n",
    "    if extra_features:\n",
    "        print(f\"⚠️ Extra features in test data (will be dropped): {extra_features}\")\n",
    "    \n",
    "    # Reorder features to match training order\n",
    "    X_test_ordered = X_test_raw[expected_feature_columns]\n",
    "    \n",
    "    # Apply scaling using fitted scaler\n",
    "    X_test_scaled = scaler.transform(X_test_ordered)\n",
    "    \n",
    "    # Convert to format expected by PyTorch\n",
    "    X_test_processed = np.array(X_test_scaled, dtype=np.float32)\n",
    "    \n",
    "    print(f\"✅ Test data preprocessed: {X_test_processed.shape}\")\n",
    "    print(f\"📊 Feature order verified: {len(expected_feature_columns)} features\")\n",
    "    \n",
    "    return X_test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ffb5786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_loaded_model(model, scaler, feature_columns, X_test_engineered):\n",
    "    \"\"\"\n",
    "    Make predictions using loaded model with proper preprocessing.\n",
    "    \n",
    "    Parameters:\n",
    "    model: Loaded PyTorch model\n",
    "    scaler: Fitted scaler from training\n",
    "    feature_columns: Expected feature order from training\n",
    "    X_test_engineered: Test data after feature engineering (DataFrame)\n",
    "    \n",
    "    Returns:\n",
    "    y_pred: Binary predictions\n",
    "    y_pred_proba: Prediction probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    X_test_processed = preprocess_test_data_for_loaded_model(\n",
    "        X_test_engineered, scaler, feature_columns\n",
    "    )\n",
    "    \n",
    "    if X_test_processed is None:\n",
    "        print(\"❌ Preprocessing failed\")\n",
    "        return None, None\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "    \n",
    "    print(f\"✅ Predictions completed: {len(y_pred)} samples\")\n",
    "    \n",
    "    return y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "60b134d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training new model with performance tracking...\n",
      "✅ Using device: cuda\n",
      "🚀 GPU: NVIDIA GeForce RTX 3080\n",
      "✅ Model configured for 30 features\n",
      "🔧 Parameter grid: 36 combinations\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved in directory: LR_model_250604-220510_F1-0-8986/\n",
      "📁 Model file: LR_model_250604-220510_F1-0-8986.pth\n",
      "🔧 Scaler: scaler.pkl\n",
      "📋 Features: feature_columns.pkl\n",
      "📋 Metadata: metadata.json\n",
      "📈 Performance metrics appended to c:\\Users\\Craig\\Documents\\Python\\msc_ai_module\\models_performance\\model_performance_log.csv\n",
      "✅ Logged performance for LR_model_250604-220510_F1-0-8986\n",
      "   🎯 Test F1: 0.9002\n",
      "   ⏱️  Training time: 611.7s\n",
      "   🔍 Specificity: 0.6725\n",
      "✅ Ready to use model with F1: 0.8986\n",
      "🏆 Best parameters: {'batch_size': 64, 'lr': 0.01, 'max_epochs': 50, 'optimizer__weight_decay': 0.001}\n",
      "📈 Best CV F1-score: 0.8986\n",
      "📊 Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.67      0.75       284\n",
      "         1.0       0.86      0.95      0.90       601\n",
      "\n",
      "    accuracy                           0.86       885\n",
      "   macro avg       0.86      0.81      0.83       885\n",
      "weighted avg       0.86      0.86      0.85       885\n",
      "\n",
      "\n",
      "🔢 Confusion Matrix:\n",
      "[[191  93]\n",
      " [ 33 568]]\n"
     ]
    }
   ],
   "source": [
    "# Configuration flag\n",
    "train_new_model = True  # Set to True to train new model, False to load best existing\n",
    "param_profile = 'pytorch_logistic_regression_quick'  # Profile to use for training\n",
    "\n",
    "# Convert data to required format\n",
    "X_train_clean = np.array(X_train_scaled, dtype=np.float32)\n",
    "y_train_clean = np.array(y_train, dtype=np.float32)\n",
    "X_test_clean = np.array(X_test_scaled, dtype=np.float32)\n",
    "y_test_clean = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "# FIXED: Store feature columns for saving with model\n",
    "feature_columns = X_train.columns.tolist()  # Before scaling, get column names\n",
    "\n",
    "# Main logic with performance tracking\n",
    "if train_new_model:\n",
    "    print(\"🚀 Training new model with performance tracking...\")\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Setup and train model\n",
    "    grid_search = setup_pytorch_logistic_regression_from_config(\n",
    "        config, X_train_clean, device='cuda', param_profile=param_profile\n",
    "    )\n",
    "    grid_search.fit(X_train_clean, y_train_clean)\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # FIXED: Save model with complete preprocessing pipeline\n",
    "    model_path, metadata_path = save_pytorch_model_with_timestamp(\n",
    "        grid_search, models_dir, scaler, feature_columns, logistic_config\n",
    "    )\n",
    "    \n",
    "    # Get model name from path\n",
    "    model_name = os.path.basename(os.path.dirname(model_path))\n",
    "    \n",
    "    # Make predictions\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_clean)\n",
    "    y_pred_proba = best_model.predict_proba(X_test_clean)[:, 1]\n",
    "    \n",
    "    # Log performance to CSV\n",
    "    csv_path = save_model_performance_to_csv(\n",
    "        model_name=model_name,\n",
    "        training_time=training_time,\n",
    "        best_cv_score=grid_search.best_score_,\n",
    "        best_params=grid_search.best_params_,\n",
    "        y_test=y_test_clean,\n",
    "        y_pred=y_pred,\n",
    "        models_performance_dir=models_performance,\n",
    "        additional_metrics={'param_profile': param_profile}\n",
    "    )\n",
    "    \n",
    "    f1_score = grid_search.best_score_\n",
    "    \n",
    "else:\n",
    "    print(\"📂 Loading best existing model...\")\n",
    "    result = load_best_pytorch_model(models_dir)\n",
    "    \n",
    "    if result is None:\n",
    "        print(\"🚀 No models found, training new one...\")\n",
    "        # Fallback to training with logging\n",
    "        start_time = time.time()\n",
    "        grid_search = setup_pytorch_logistic_regression_from_config(\n",
    "            config, X_train_clean, device='cuda', param_profile=param_profile\n",
    "        )\n",
    "        grid_search.fit(X_train_clean, y_train_clean)\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # FIXED: Save with complete pipeline\n",
    "        model_path, metadata_path = save_pytorch_model_with_timestamp(\n",
    "            grid_search, models_dir, scaler, feature_columns, logistic_config\n",
    "        )\n",
    "        model_name = os.path.basename(os.path.dirname(model_path))\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test_clean)\n",
    "        \n",
    "        save_model_performance_to_csv(\n",
    "            model_name=model_name,\n",
    "            training_time=training_time,\n",
    "            best_cv_score=grid_search.best_score_,\n",
    "            best_params=grid_search.best_params_,\n",
    "            y_test=y_test_clean,\n",
    "            y_pred=y_pred,\n",
    "            models_performance_dir=models_performance,\n",
    "            additional_metrics={'param_profile': param_profile}\n",
    "        )\n",
    "        \n",
    "        f1_score = grid_search.best_score_\n",
    "        best_metadata = None\n",
    "        loaded_scaler = scaler\n",
    "        loaded_feature_columns = feature_columns\n",
    "    else:\n",
    "        # FIXED: Unpack all components from loaded model\n",
    "        best_model, best_metadata, loaded_scaler, loaded_feature_columns = result\n",
    "        f1_score = best_metadata['f1_score']\n",
    "        \n",
    "        # FIXED: Use proper preprocessing for loaded model\n",
    "        print(\"🔧 Applying loaded model preprocessing...\")\n",
    "        y_pred, y_pred_proba = predict_with_loaded_model(\n",
    "            best_model, loaded_scaler, loaded_feature_columns, X_test\n",
    "        )\n",
    "\n",
    "print(f\"✅ Ready to use model with F1: {f1_score:.4f}\")\n",
    "\n",
    "# FIXED: Performance evaluation with properly preprocessed data\n",
    "if train_new_model or (not train_new_model and result is None):\n",
    "    # For newly trained models, use existing predictions\n",
    "    print(f\"🏆 Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"📈 Best CV F1-score: {grid_search.best_score_:.4f}\")\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predictions already made above\n",
    "    if 'y_pred' not in locals():\n",
    "        y_pred = best_model.predict(X_test_clean)\n",
    "        y_pred_proba = best_model.predict_proba(X_test_clean)[:, 1]\n",
    "        \n",
    "else:\n",
    "    # For loaded models, predictions made with proper preprocessing\n",
    "    print(f\"🏆 Best parameters: {best_metadata['best_params']}\")\n",
    "    print(f\"📈 Best CV F1-score: {best_metadata['f1_score']:.4f}\")\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"📊 Test Set Performance:\")\n",
    "print(classification_report(y_test_clean, y_pred))\n",
    "print(\"\\n🔢 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_clean, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bfb8509b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing Model Loading Fix...\n",
      "\n",
      "1️⃣ Testing model loading...\n",
      "📂 Loaded model from directory: LR_model_250604-220510_F1-0-8986/\n",
      "🏆 F1 Score: 0.8986\n",
      "⚙️ Parameters: {'batch_size': 64, 'lr': 0.01, 'max_epochs': 50, 'optimizer__weight_decay': 0.001}\n",
      "🔧 Scaler type: standard\n",
      "📊 Features: 30\n",
      "✅ Model loaded successfully\n",
      "📊 Features expected: 30\n",
      "🔧 Scaler type: StandardScaler\n",
      "\n",
      "2️⃣ Testing feature alignment...\n",
      "Training features: 30\n",
      "Test features: 30\n",
      "✅ Perfect feature alignment\n",
      "\n",
      "3️⃣ Testing preprocessing pipeline...\n",
      "✅ Test data preprocessed: (885, 30)\n",
      "📊 Feature order verified: 30 features\n",
      "✅ Preprocessing successful: (885, 30)\n",
      "📊 Data type: float32\n",
      "📊 Value range: [-2.725, 26.586]\n",
      "\n",
      "4️⃣ Testing predictions...\n",
      "✅ Test data preprocessed: (885, 30)\n",
      "📊 Feature order verified: 30 features\n",
      "✅ Predictions completed: 885 samples\n",
      "✅ Predictions successful: 885 samples\n",
      "📊 Prediction distribution: (array([0, 1]), array([224, 661]))\n",
      "📊 Probability range: [0.001, 0.990]\n",
      "\n",
      "📈 Quick Performance Check:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.67      0.75       284\n",
      "           1       0.86      0.95      0.90       601\n",
      "\n",
      "    accuracy                           0.86       885\n",
      "   macro avg       0.86      0.81      0.83       885\n",
      "weighted avg       0.86      0.86      0.85       885\n",
      "\n",
      "\n",
      "🏁 Test completed!\n"
     ]
    }
   ],
   "source": [
    "# Test script to verify the model loading fix\n",
    "print(\"🧪 Testing Model Loading Fix...\")\n",
    "\n",
    "# Test 1: Load model and check components\n",
    "print(\"\\n1️⃣ Testing model loading...\")\n",
    "result = load_best_pytorch_model(models_dir)\n",
    "\n",
    "if result is None:\n",
    "    print(\"❌ No model found - need to train first\")\n",
    "else:\n",
    "    model, metadata, scaler, feature_columns = result\n",
    "    print(f\"✅ Model loaded successfully\")\n",
    "    print(f\"📊 Features expected: {len(feature_columns)}\")\n",
    "    print(f\"🔧 Scaler type: {type(scaler).__name__}\")\n",
    "\n",
    "# Test 2: Check feature alignment\n",
    "print(\"\\n2️⃣ Testing feature alignment...\")\n",
    "if result is not None:\n",
    "    print(f\"Training features: {len(feature_columns)}\")\n",
    "    print(f\"Test features: {len(X_test.columns)}\")\n",
    "    \n",
    "    missing = set(feature_columns) - set(X_test.columns)\n",
    "    extra = set(X_test.columns) - set(feature_columns)\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"❌ Missing features: {missing}\")\n",
    "    if extra:\n",
    "        print(f\"⚠️ Extra features: {extra}\")\n",
    "    if not missing and not extra:\n",
    "        print(\"✅ Perfect feature alignment\")\n",
    "\n",
    "# Test 3: Test preprocessing\n",
    "print(\"\\n3️⃣ Testing preprocessing pipeline...\")\n",
    "if result is not None:\n",
    "    try:\n",
    "        X_test_processed = preprocess_test_data_for_loaded_model(\n",
    "            X_test, scaler, feature_columns\n",
    "        )\n",
    "        if X_test_processed is not None:\n",
    "            print(f\"✅ Preprocessing successful: {X_test_processed.shape}\")\n",
    "            print(f\"📊 Data type: {X_test_processed.dtype}\")\n",
    "            print(f\"📊 Value range: [{X_test_processed.min():.3f}, {X_test_processed.max():.3f}]\")\n",
    "        else:\n",
    "            print(\"❌ Preprocessing failed\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Preprocessing error: {e}\")\n",
    "\n",
    "# Test 4: Test predictions\n",
    "print(\"\\n4️⃣ Testing predictions...\")\n",
    "if result is not None:\n",
    "    try:\n",
    "        y_pred_test, y_proba_test = predict_with_loaded_model(\n",
    "            model, scaler, feature_columns, X_test\n",
    "        )\n",
    "        \n",
    "        if y_pred_test is not None:\n",
    "            print(f\"✅ Predictions successful: {len(y_pred_test)} samples\")\n",
    "            print(f\"📊 Prediction distribution: {np.unique(y_pred_test, return_counts=True)}\")\n",
    "            print(f\"📊 Probability range: [{y_proba_test.min():.3f}, {y_proba_test.max():.3f}]\")\n",
    "            \n",
    "            # Quick performance check\n",
    "            from sklearn.metrics import classification_report\n",
    "            print(\"\\n📈 Quick Performance Check:\")\n",
    "            print(classification_report(y_test, y_pred_test))\n",
    "        else:\n",
    "            print(\"❌ Predictions failed\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Prediction error: {e}\")\n",
    "\n",
    "print(\"\\n🏁 Test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a1017164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test data to same format\n",
    "# X_test_clean = np.array(X_test, dtype=np.float32)\n",
    "y_test_clean = np.array(y_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bf421665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Best parameters: {'batch_size': 64, 'lr': 0.01, 'max_epochs': 50, 'optimizer__weight_decay': 0.001}\n",
      "📈 Best CV F1-score: 0.8986\n"
     ]
    }
   ],
   "source": [
    "# For LOADED models, use metadata\n",
    "if not train_new_model and result is not None:\n",
    "    best_model, metadata, loaded_scaler, loaded_feature_columns = result\n",
    "    print(f\"🏆 Best parameters: {metadata['best_params']}\")\n",
    "    print(f\"📈 Best CV F1-score: {metadata['f1_score']:.4f}\")\n",
    "\n",
    "# For TRAINED models, use grid_search\n",
    "elif train_new_model or (not train_new_model and result is None):\n",
    "    print(f\"🏆 Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"📈 Best CV F1-score: {grid_search.best_score_:.4f}\")\n",
    "    best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "da3a95d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Best parameters: {'batch_size': 64, 'lr': 0.01, 'max_epochs': 50, 'optimizer__weight_decay': 0.001}\n",
      "📈 Best CV F1-score: 0.8986\n",
      "📊 Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.67      0.75       284\n",
      "         1.0       0.86      0.95      0.90       601\n",
      "\n",
      "    accuracy                           0.86       885\n",
      "   macro avg       0.86      0.81      0.83       885\n",
      "weighted avg       0.86      0.86      0.85       885\n",
      "\n",
      "\n",
      "🔢 Confusion Matrix:\n",
      "[[191  93]\n",
      " [ 33 568]]\n"
     ]
    }
   ],
   "source": [
    "# FIXED: Use correct preprocessing based on model source\n",
    "if not train_new_model and result is not None:\n",
    "    # For LOADED models - use proper preprocessing pipeline\n",
    "    best_model, metadata, loaded_scaler, loaded_feature_columns = result\n",
    "    print(f\"🏆 Best parameters: {metadata['best_params']}\")\n",
    "    print(f\"📈 Best CV F1-score: {metadata['f1_score']:.4f}\")\n",
    "    \n",
    "    # Use loaded model's preprocessing (THIS GIVES GOOD PERFORMANCE)\n",
    "    print(\"🔧 Using loaded model preprocessing...\")\n",
    "    y_pred, y_pred_proba = predict_with_loaded_model(\n",
    "        best_model, loaded_scaler, loaded_feature_columns, X_test\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    # For NEWLY TRAINED models - use training data\n",
    "    print(f\"🏆 Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"📈 Best CV F1-score: {grid_search.best_score_:.4f}\")\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Use training session data\n",
    "    y_pred = best_model.predict(X_test_clean)\n",
    "    y_pred_proba = best_model.predict_proba(X_test_clean)[:, 1]\n",
    "\n",
    "# Performance metrics (works for both cases)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"📊 Test Set Performance:\")\n",
    "print(classification_report(y_test_clean, y_pred))\n",
    "print(\"\\n🔢 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_clean, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557ff21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
